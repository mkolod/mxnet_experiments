{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from collections import namedtuple, Counter\n",
    "from unidecode import unidecode\n",
    "from mxnet.io import DataIter\n",
    "\n",
    "import operator\n",
    "import pickle\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get rid of annoying Python deprecation warnings from built-in JSON encoder\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Args = namedtuple(\n",
    "    'Args', \n",
    "    ('test load_epoch num_layers num_hidden num_embed bidirectional gpus '\n",
    "     'kv_store num_epochs optimizer mom wd lr batch_size disp_batches '\n",
    "     'stack_rnn dropout model_prefix'))\n",
    "\n",
    "args = Args(\n",
    "    test=          False,\n",
    "    load_epoch=    0,\n",
    "    num_layers=    2,\n",
    "    num_hidden=    200,\n",
    "    num_embed=     200,\n",
    "    bidirectional= False,\n",
    "    gpus=          '0,1',\n",
    "    kv_store=      'device',\n",
    "    num_epochs=    1,\n",
    "    optimizer=    'adam',\n",
    "    mom=           0.9,\n",
    "    wd=           0.00001,\n",
    "    lr = 0.001,\n",
    "    batch_size=    32,\n",
    "    disp_batches=  50,\n",
    "    stack_rnn=     False,\n",
    "    dropout=       0.5,\n",
    "    model_prefix= 'foo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do a word count to get the number of words \n",
    "\n",
    "# Decode text as UTF-8\n",
    "# Remove diacritical signs and convert to Latin alphabet\n",
    "# Separate punctuation as separate \"words\"\n",
    "def tokenize_text(fname, vocab=None, invalid_label=0, start_label=1, sep_punctuation=True):\n",
    "    lines = unidecode(open(fname).read().decode('utf-8')).split('\\n')\n",
    "    lines = [x for x in lines if x]\n",
    "    lines = map(lambda x: re.findall(r\"\\w+|[^\\w\\s]\", x, re.UNICODE), lines)    \n",
    "    sentences, vocab = mx.rnn.encode_sentences(lines, vocab=vocab, invalid_label=invalid_label, start_label=start_label)\n",
    "    return sentences, vocab\n",
    "\n",
    "Dataset = namedtuple('Dataset', ['src_sent', 'src_vocab', 'targ_sent', 'targ_vocab'])\n",
    "\n",
    "def get_data(src_path, targ_path, start_label=1, invalid_label=0):\n",
    "    src_sent, src_vocab = tokenize_text(src_path, start_label=start_label,\n",
    "                                invalid_label=invalid_label)\n",
    "    \n",
    "    targ_sent, targ_vocab = tokenize_text(targ_path, start_label=start_label, #new_start+1,\n",
    "                                          invalid_label=invalid_label)\n",
    "\n",
    "    return Dataset(src_sent=src_sent, src_vocab=src_vocab, targ_sent=targ_sent, targ_vocab=targ_vocab)\n",
    "\n",
    "def persist_dataset(dataset, path):\n",
    "    with open(path, 'wb+') as fileobj:\n",
    "        pickle.dump(dataset, fileobj)\n",
    "        \n",
    "def load_dataset(path):\n",
    "    with open(path, 'rb') as fileobj:\n",
    "        return pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset = \\\n",
    "    get_data(\n",
    "        src_path='./data/europarl-v7.es-en.en_vsmall',\n",
    "        targ_path='./data/europarl-v7.es-en.es_vsmall',\n",
    "        start_label=1,\n",
    "        invalid_label=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './foo.pickle'\n",
    "persist_dataset(dataset, path)\n",
    "dataset2 = load_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_buckets(src_sent, targ_sent, filter_smaller_counts_than=None, max_sent_len=60, min_sent_len=1):\n",
    "    length_pairs = map(lambda x: (len(x[0]), len(x[1])), zip(src_sent, targ_sent))\n",
    "    counts = list(Counter(length_pairs).items())\n",
    "    c_sorted = sorted(counts, key=operator.itemgetter(0, 1))\n",
    "    buckets = [i for i in c_sorted if i[1] >= filter_smaller_counts_than and \n",
    "               i[0][0] <= max_sent_len and i[0][1] <= max_sent_len and\n",
    "               i[0][0] >= min_sent_len and i[0][1] >= min_sent_len]\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen_buckets(dataset, filter_smaller_counts_than=None, max_sent_len=60, min_sent_len=1):\n",
    "    src_sent = dataset.src_sent\n",
    "    targ_sent = dataset.targ_sent\n",
    "    length_pairs = map(lambda x: (len(x[0]), len(x[1])), zip(src_sent, targ_sent))\n",
    "    counts = list(Counter(length_pairs).items())\n",
    "    c_sorted = sorted(counts, key=operator.itemgetter(0, 1))\n",
    "    buckets = [i for i in c_sorted if i[1] >= filter_smaller_counts_than and \n",
    "               (max_sent_len is None or i[0][0] <= max_sent_len) and\n",
    "               (max_sent_len is None or i[0][1] <= max_sent_len) and\n",
    "               (min_sent_len is None or i[0][0] >= min_sent_len) and\n",
    "               (min_sent_len is None or i[0][1] >= min_sent_len)]\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_buckets = gen_buckets(dataset, filter_smaller_counts_than=None, max_sent_len=None, min_sent_len=None)\n",
    "batch_size = 32\n",
    "batched_buckets = gen_buckets(dataset, filter_smaller_counts_than=batch_size, max_sent_len=60, min_sent_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), 5),\n",
       " ((1, 4), 2),\n",
       " ((1, 5), 3),\n",
       " ((1, 6), 1),\n",
       " ((1, 7), 4),\n",
       " ((1, 8), 3),\n",
       " ((1, 9), 2),\n",
       " ((1, 10), 1),\n",
       " ((1, 11), 3),\n",
       " ((1, 12), 6),\n",
       " ((1, 13), 2),\n",
       " ((1, 14), 5),\n",
       " ((1, 15), 7),\n",
       " ((1, 16), 4),\n",
       " ((1, 17), 4),\n",
       " ((1, 18), 6),\n",
       " ((1, 19), 2),\n",
       " ((1, 20), 5),\n",
       " ((1, 21), 2),\n",
       " ((1, 22), 7),\n",
       " ((1, 23), 5),\n",
       " ((1, 24), 3),\n",
       " ((1, 25), 4),\n",
       " ((1, 26), 4),\n",
       " ((1, 27), 3),\n",
       " ((1, 28), 2),\n",
       " ((1, 29), 4),\n",
       " ((1, 30), 2),\n",
       " ((1, 31), 4),\n",
       " ((1, 32), 1),\n",
       " ((1, 33), 2),\n",
       " ((1, 34), 2),\n",
       " ((1, 35), 2),\n",
       " ((1, 36), 3),\n",
       " ((1, 37), 2),\n",
       " ((1, 38), 5),\n",
       " ((1, 39), 3),\n",
       " ((1, 40), 3),\n",
       " ((1, 42), 2),\n",
       " ((1, 43), 1),\n",
       " ((1, 44), 1),\n",
       " ((1, 45), 1),\n",
       " ((1, 46), 2),\n",
       " ((1, 48), 2),\n",
       " ((1, 49), 3),\n",
       " ((1, 50), 1),\n",
       " ((1, 51), 4),\n",
       " ((1, 52), 2),\n",
       " ((1, 53), 1),\n",
       " ((1, 54), 2),\n",
       " ((1, 55), 2),\n",
       " ((1, 56), 4),\n",
       " ((1, 58), 1),\n",
       " ((1, 60), 1),\n",
       " ((1, 61), 1),\n",
       " ((1, 63), 1),\n",
       " ((1, 64), 2),\n",
       " ((1, 70), 1),\n",
       " ((1, 73), 1),\n",
       " ((1, 74), 1),\n",
       " ((1, 75), 1),\n",
       " ((1, 83), 1),\n",
       " ((1, 84), 1),\n",
       " ((1, 87), 1),\n",
       " ((1, 89), 1),\n",
       " ((1, 90), 1),\n",
       " ((1, 99), 1),\n",
       " ((1, 124), 1),\n",
       " ((1, 137), 1),\n",
       " ((2, 6), 1),\n",
       " ((2, 9), 3),\n",
       " ((2, 10), 2),\n",
       " ((2, 11), 1),\n",
       " ((2, 12), 5),\n",
       " ((2, 13), 2),\n",
       " ((2, 14), 3),\n",
       " ((2, 15), 1),\n",
       " ((2, 16), 2),\n",
       " ((2, 18), 1),\n",
       " ((2, 19), 2),\n",
       " ((2, 20), 2),\n",
       " ((2, 22), 1),\n",
       " ((2, 24), 1),\n",
       " ((2, 25), 2),\n",
       " ((2, 26), 2),\n",
       " ((2, 27), 1),\n",
       " ((2, 29), 3),\n",
       " ((2, 31), 1),\n",
       " ((2, 34), 1),\n",
       " ((2, 37), 3),\n",
       " ((2, 38), 4),\n",
       " ((2, 39), 1),\n",
       " ((2, 40), 2),\n",
       " ((2, 41), 2),\n",
       " ((2, 44), 1),\n",
       " ((2, 45), 1),\n",
       " ((2, 49), 1),\n",
       " ((2, 52), 1),\n",
       " ((2, 54), 2),\n",
       " ((2, 57), 1),\n",
       " ((2, 67), 1),\n",
       " ((2, 75), 1),\n",
       " ((2, 82), 1),\n",
       " ((3, 3), 1),\n",
       " ((3, 4), 2),\n",
       " ((3, 5), 1),\n",
       " ((3, 6), 1),\n",
       " ((3, 7), 2),\n",
       " ((3, 9), 4),\n",
       " ((3, 10), 1),\n",
       " ((3, 11), 1),\n",
       " ((3, 12), 1),\n",
       " ((3, 13), 2),\n",
       " ((3, 14), 4),\n",
       " ((3, 15), 3),\n",
       " ((3, 16), 3),\n",
       " ((3, 17), 3),\n",
       " ((3, 18), 5),\n",
       " ((3, 19), 2),\n",
       " ((3, 20), 2),\n",
       " ((3, 22), 2),\n",
       " ((3, 23), 2),\n",
       " ((3, 24), 4),\n",
       " ((3, 25), 5),\n",
       " ((3, 26), 2),\n",
       " ((3, 27), 3),\n",
       " ((3, 28), 2),\n",
       " ((3, 30), 1),\n",
       " ((3, 31), 9),\n",
       " ((3, 33), 1),\n",
       " ((3, 34), 4),\n",
       " ((3, 36), 2),\n",
       " ((3, 37), 3),\n",
       " ((3, 38), 2),\n",
       " ((3, 41), 1),\n",
       " ((3, 42), 2),\n",
       " ((3, 44), 1),\n",
       " ((3, 46), 4),\n",
       " ((3, 48), 3),\n",
       " ((3, 49), 1),\n",
       " ((3, 50), 1),\n",
       " ((3, 53), 3),\n",
       " ((3, 58), 2),\n",
       " ((3, 60), 1),\n",
       " ((3, 67), 1),\n",
       " ((3, 75), 1),\n",
       " ((3, 82), 1),\n",
       " ((3, 90), 1),\n",
       " ((4, 2), 2),\n",
       " ((4, 3), 2),\n",
       " ((4, 5), 4),\n",
       " ((4, 6), 3),\n",
       " ((4, 7), 2),\n",
       " ((4, 8), 6),\n",
       " ((4, 9), 3),\n",
       " ((4, 10), 5),\n",
       " ((4, 11), 9),\n",
       " ((4, 12), 7),\n",
       " ((4, 13), 3),\n",
       " ((4, 14), 4),\n",
       " ((4, 15), 6),\n",
       " ((4, 16), 3),\n",
       " ((4, 17), 3),\n",
       " ((4, 18), 6),\n",
       " ((4, 19), 2),\n",
       " ((4, 20), 6),\n",
       " ((4, 21), 9),\n",
       " ((4, 22), 4),\n",
       " ((4, 23), 8),\n",
       " ((4, 24), 7),\n",
       " ((4, 25), 4),\n",
       " ((4, 26), 8),\n",
       " ((4, 27), 6),\n",
       " ((4, 28), 7),\n",
       " ((4, 29), 3),\n",
       " ((4, 30), 6),\n",
       " ((4, 31), 3),\n",
       " ((4, 32), 3),\n",
       " ((4, 33), 4),\n",
       " ((4, 34), 2),\n",
       " ((4, 35), 2),\n",
       " ((4, 36), 2),\n",
       " ((4, 37), 5),\n",
       " ((4, 38), 2),\n",
       " ((4, 39), 3),\n",
       " ((4, 40), 1),\n",
       " ((4, 41), 5),\n",
       " ((4, 42), 2),\n",
       " ((4, 44), 3),\n",
       " ((4, 45), 2),\n",
       " ((4, 46), 1),\n",
       " ((4, 47), 2),\n",
       " ((4, 48), 1),\n",
       " ((4, 49), 1),\n",
       " ((4, 51), 1),\n",
       " ((4, 53), 3),\n",
       " ((4, 56), 2),\n",
       " ((4, 59), 2),\n",
       " ((4, 60), 1),\n",
       " ((4, 61), 1),\n",
       " ((4, 62), 1),\n",
       " ((4, 65), 2),\n",
       " ((4, 66), 1),\n",
       " ((4, 70), 1),\n",
       " ((4, 73), 1),\n",
       " ((4, 77), 2),\n",
       " ((4, 78), 2),\n",
       " ((5, 3), 3),\n",
       " ((5, 4), 5),\n",
       " ((5, 5), 6),\n",
       " ((5, 6), 10),\n",
       " ((5, 7), 7),\n",
       " ((5, 8), 9),\n",
       " ((5, 9), 8),\n",
       " ((5, 10), 10),\n",
       " ((5, 11), 10),\n",
       " ((5, 12), 17),\n",
       " ((5, 13), 15),\n",
       " ((5, 14), 20),\n",
       " ((5, 15), 9),\n",
       " ((5, 16), 14),\n",
       " ((5, 17), 19),\n",
       " ((5, 18), 16),\n",
       " ((5, 19), 12),\n",
       " ((5, 20), 9),\n",
       " ((5, 21), 9),\n",
       " ((5, 22), 8),\n",
       " ((5, 23), 16),\n",
       " ((5, 24), 8),\n",
       " ((5, 25), 7),\n",
       " ((5, 26), 7),\n",
       " ((5, 27), 15),\n",
       " ((5, 28), 9),\n",
       " ((5, 29), 5),\n",
       " ((5, 30), 15),\n",
       " ((5, 31), 12),\n",
       " ((5, 32), 15),\n",
       " ((5, 33), 7),\n",
       " ((5, 34), 7),\n",
       " ((5, 35), 10),\n",
       " ((5, 36), 10),\n",
       " ((5, 37), 7),\n",
       " ((5, 38), 6),\n",
       " ((5, 39), 5),\n",
       " ((5, 40), 7),\n",
       " ((5, 41), 6),\n",
       " ((5, 42), 6),\n",
       " ((5, 43), 2),\n",
       " ((5, 44), 11),\n",
       " ((5, 45), 8),\n",
       " ((5, 46), 1),\n",
       " ((5, 47), 5),\n",
       " ((5, 48), 3),\n",
       " ((5, 49), 5),\n",
       " ((5, 50), 7),\n",
       " ((5, 51), 2),\n",
       " ((5, 52), 5),\n",
       " ((5, 53), 4),\n",
       " ((5, 54), 4),\n",
       " ((5, 55), 6),\n",
       " ((5, 56), 1),\n",
       " ((5, 57), 1),\n",
       " ((5, 58), 3),\n",
       " ((5, 59), 2),\n",
       " ((5, 60), 3),\n",
       " ((5, 61), 6),\n",
       " ((5, 62), 4),\n",
       " ((5, 63), 1),\n",
       " ((5, 65), 1),\n",
       " ((5, 67), 3),\n",
       " ((5, 68), 1),\n",
       " ((5, 69), 2),\n",
       " ((5, 70), 1),\n",
       " ((5, 71), 2),\n",
       " ((5, 72), 1),\n",
       " ((5, 73), 1),\n",
       " ((5, 77), 2),\n",
       " ((5, 78), 1),\n",
       " ((5, 81), 1),\n",
       " ((5, 83), 1),\n",
       " ((5, 89), 1),\n",
       " ((5, 92), 1),\n",
       " ((5, 93), 1),\n",
       " ((5, 94), 1),\n",
       " ((5, 97), 1),\n",
       " ((5, 119), 1),\n",
       " ((5, 124), 1),\n",
       " ((5, 138), 1),\n",
       " ((6, 1), 6),\n",
       " ((6, 3), 2),\n",
       " ((6, 4), 3),\n",
       " ((6, 5), 6),\n",
       " ((6, 6), 11),\n",
       " ((6, 7), 12),\n",
       " ((6, 8), 17),\n",
       " ((6, 9), 11),\n",
       " ((6, 10), 16),\n",
       " ((6, 11), 18),\n",
       " ((6, 12), 27),\n",
       " ((6, 13), 18),\n",
       " ((6, 14), 14),\n",
       " ((6, 15), 7),\n",
       " ((6, 16), 26),\n",
       " ((6, 17), 13),\n",
       " ((6, 18), 24),\n",
       " ((6, 19), 16),\n",
       " ((6, 20), 7),\n",
       " ((6, 21), 16),\n",
       " ((6, 22), 22),\n",
       " ((6, 23), 19),\n",
       " ((6, 24), 16),\n",
       " ((6, 25), 11),\n",
       " ((6, 26), 12),\n",
       " ((6, 27), 10),\n",
       " ((6, 28), 8),\n",
       " ((6, 29), 15),\n",
       " ((6, 30), 12),\n",
       " ((6, 31), 17),\n",
       " ((6, 32), 8),\n",
       " ((6, 33), 18),\n",
       " ((6, 34), 14),\n",
       " ((6, 35), 10),\n",
       " ((6, 36), 12),\n",
       " ((6, 37), 5),\n",
       " ((6, 38), 10),\n",
       " ((6, 39), 7),\n",
       " ((6, 40), 7),\n",
       " ((6, 41), 5),\n",
       " ((6, 42), 6),\n",
       " ((6, 43), 9),\n",
       " ((6, 44), 8),\n",
       " ((6, 45), 12),\n",
       " ((6, 46), 7),\n",
       " ((6, 47), 6),\n",
       " ((6, 48), 3),\n",
       " ((6, 49), 10),\n",
       " ((6, 50), 3),\n",
       " ((6, 51), 8),\n",
       " ((6, 52), 4),\n",
       " ((6, 53), 2),\n",
       " ((6, 54), 2),\n",
       " ((6, 55), 2),\n",
       " ((6, 56), 4),\n",
       " ((6, 57), 4),\n",
       " ((6, 58), 1),\n",
       " ((6, 59), 3),\n",
       " ((6, 60), 6),\n",
       " ((6, 61), 3),\n",
       " ((6, 62), 4),\n",
       " ((6, 63), 1),\n",
       " ((6, 65), 2),\n",
       " ((6, 66), 1),\n",
       " ((6, 68), 1),\n",
       " ((6, 69), 2),\n",
       " ((6, 70), 2),\n",
       " ((6, 71), 1),\n",
       " ((6, 73), 3),\n",
       " ((6, 74), 3),\n",
       " ((6, 75), 1),\n",
       " ((6, 78), 2),\n",
       " ((6, 79), 1),\n",
       " ((6, 81), 2),\n",
       " ((6, 83), 2),\n",
       " ((6, 90), 1),\n",
       " ((6, 91), 1),\n",
       " ((6, 92), 1),\n",
       " ((6, 96), 1),\n",
       " ((6, 112), 1),\n",
       " ((6, 118), 1),\n",
       " ((6, 119), 1),\n",
       " ((6, 130), 1),\n",
       " ((6, 151), 1),\n",
       " ((7, 1), 2),\n",
       " ((7, 2), 1),\n",
       " ((7, 3), 4),\n",
       " ((7, 4), 4),\n",
       " ((7, 5), 12),\n",
       " ((7, 6), 5),\n",
       " ((7, 7), 12),\n",
       " ((7, 8), 21),\n",
       " ((7, 9), 19),\n",
       " ((7, 10), 18),\n",
       " ((7, 11), 17),\n",
       " ((7, 12), 13),\n",
       " ((7, 13), 20),\n",
       " ((7, 14), 17),\n",
       " ((7, 15), 22),\n",
       " ((7, 16), 27),\n",
       " ((7, 17), 23),\n",
       " ((7, 18), 17),\n",
       " ((7, 19), 15),\n",
       " ((7, 20), 16),\n",
       " ((7, 21), 16),\n",
       " ((7, 22), 21),\n",
       " ((7, 23), 20),\n",
       " ((7, 24), 21),\n",
       " ((7, 25), 16),\n",
       " ((7, 26), 19),\n",
       " ((7, 27), 10),\n",
       " ((7, 28), 9),\n",
       " ((7, 29), 17),\n",
       " ((7, 30), 12),\n",
       " ((7, 31), 11),\n",
       " ((7, 32), 10),\n",
       " ((7, 33), 11),\n",
       " ((7, 34), 16),\n",
       " ((7, 35), 9),\n",
       " ((7, 36), 14),\n",
       " ((7, 37), 20),\n",
       " ((7, 38), 11),\n",
       " ((7, 39), 11),\n",
       " ((7, 40), 9),\n",
       " ((7, 41), 7),\n",
       " ((7, 42), 8),\n",
       " ((7, 43), 4),\n",
       " ((7, 44), 8),\n",
       " ((7, 45), 8),\n",
       " ((7, 46), 9),\n",
       " ((7, 47), 7),\n",
       " ((7, 48), 3),\n",
       " ((7, 49), 7),\n",
       " ((7, 50), 3),\n",
       " ((7, 51), 9),\n",
       " ((7, 52), 7),\n",
       " ((7, 53), 7),\n",
       " ((7, 54), 7),\n",
       " ((7, 55), 6),\n",
       " ((7, 56), 4),\n",
       " ((7, 57), 5),\n",
       " ((7, 59), 1),\n",
       " ((7, 60), 1),\n",
       " ((7, 61), 3),\n",
       " ((7, 62), 3),\n",
       " ((7, 63), 1),\n",
       " ((7, 64), 3),\n",
       " ((7, 66), 1),\n",
       " ((7, 67), 2),\n",
       " ((7, 68), 1),\n",
       " ((7, 69), 5),\n",
       " ((7, 70), 2),\n",
       " ((7, 72), 2),\n",
       " ((7, 73), 2),\n",
       " ((7, 74), 2),\n",
       " ((7, 76), 1),\n",
       " ((7, 77), 1),\n",
       " ((7, 80), 4),\n",
       " ((7, 81), 1),\n",
       " ((7, 82), 1),\n",
       " ((7, 83), 1),\n",
       " ((7, 84), 1),\n",
       " ((7, 85), 4),\n",
       " ((7, 87), 1),\n",
       " ((7, 88), 1),\n",
       " ((7, 90), 1),\n",
       " ((7, 91), 1),\n",
       " ((7, 93), 1),\n",
       " ((7, 95), 1),\n",
       " ((7, 99), 1),\n",
       " ((7, 101), 1),\n",
       " ((7, 119), 1),\n",
       " ((7, 145), 1),\n",
       " ((8, 1), 3),\n",
       " ((8, 3), 3),\n",
       " ((8, 4), 1),\n",
       " ((8, 5), 11),\n",
       " ((8, 6), 14),\n",
       " ((8, 7), 17),\n",
       " ((8, 8), 14),\n",
       " ((8, 9), 20),\n",
       " ((8, 10), 21),\n",
       " ((8, 11), 22),\n",
       " ((8, 12), 21),\n",
       " ((8, 13), 33),\n",
       " ((8, 14), 17),\n",
       " ((8, 15), 24),\n",
       " ((8, 16), 29),\n",
       " ((8, 17), 18),\n",
       " ((8, 18), 36),\n",
       " ((8, 19), 22),\n",
       " ((8, 20), 32),\n",
       " ((8, 21), 22),\n",
       " ((8, 22), 16),\n",
       " ((8, 23), 18),\n",
       " ((8, 24), 22),\n",
       " ((8, 25), 28),\n",
       " ((8, 26), 32),\n",
       " ((8, 27), 23),\n",
       " ((8, 28), 19),\n",
       " ((8, 29), 27),\n",
       " ((8, 30), 18),\n",
       " ((8, 31), 21),\n",
       " ((8, 32), 15),\n",
       " ((8, 33), 17),\n",
       " ((8, 34), 19),\n",
       " ((8, 35), 14),\n",
       " ((8, 36), 12),\n",
       " ((8, 37), 16),\n",
       " ((8, 38), 12),\n",
       " ((8, 39), 10),\n",
       " ((8, 40), 4),\n",
       " ((8, 41), 10),\n",
       " ((8, 42), 8),\n",
       " ((8, 43), 15),\n",
       " ((8, 44), 10),\n",
       " ((8, 45), 2),\n",
       " ((8, 46), 7),\n",
       " ((8, 47), 7),\n",
       " ((8, 48), 7),\n",
       " ((8, 49), 8),\n",
       " ((8, 50), 5),\n",
       " ((8, 51), 6),\n",
       " ((8, 52), 4),\n",
       " ((8, 53), 4),\n",
       " ((8, 54), 5),\n",
       " ((8, 55), 10),\n",
       " ((8, 56), 7),\n",
       " ((8, 57), 1),\n",
       " ((8, 58), 7),\n",
       " ((8, 59), 3),\n",
       " ((8, 60), 4),\n",
       " ((8, 61), 3),\n",
       " ((8, 62), 1),\n",
       " ((8, 63), 1),\n",
       " ((8, 64), 1),\n",
       " ((8, 65), 2),\n",
       " ((8, 66), 2),\n",
       " ((8, 67), 1),\n",
       " ((8, 68), 4),\n",
       " ((8, 69), 4),\n",
       " ((8, 70), 1),\n",
       " ((8, 72), 2),\n",
       " ((8, 73), 1),\n",
       " ((8, 75), 2),\n",
       " ((8, 76), 1),\n",
       " ((8, 77), 2),\n",
       " ((8, 78), 1),\n",
       " ((8, 79), 3),\n",
       " ((8, 80), 1),\n",
       " ((8, 82), 1),\n",
       " ((8, 83), 2),\n",
       " ((8, 85), 1),\n",
       " ((8, 91), 1),\n",
       " ((8, 92), 1),\n",
       " ((8, 94), 2),\n",
       " ((8, 98), 1),\n",
       " ((8, 120), 1),\n",
       " ((8, 124), 1),\n",
       " ((9, 1), 4),\n",
       " ((9, 2), 1),\n",
       " ((9, 3), 4),\n",
       " ((9, 4), 6),\n",
       " ((9, 5), 14),\n",
       " ((9, 6), 17),\n",
       " ((9, 7), 13),\n",
       " ((9, 8), 27),\n",
       " ((9, 9), 16),\n",
       " ((9, 10), 25),\n",
       " ((9, 11), 20),\n",
       " ((9, 12), 30),\n",
       " ((9, 13), 25),\n",
       " ((9, 14), 23),\n",
       " ((9, 15), 26),\n",
       " ((9, 16), 27),\n",
       " ((9, 17), 20),\n",
       " ((9, 18), 27),\n",
       " ((9, 19), 30),\n",
       " ((9, 20), 34),\n",
       " ((9, 21), 26),\n",
       " ((9, 22), 35),\n",
       " ((9, 23), 29),\n",
       " ((9, 24), 26),\n",
       " ((9, 25), 23),\n",
       " ((9, 26), 18),\n",
       " ((9, 27), 18),\n",
       " ((9, 28), 35),\n",
       " ((9, 29), 21),\n",
       " ((9, 30), 30),\n",
       " ((9, 31), 16),\n",
       " ((9, 32), 20),\n",
       " ((9, 33), 14),\n",
       " ((9, 34), 18),\n",
       " ((9, 35), 14),\n",
       " ((9, 36), 18),\n",
       " ((9, 37), 15),\n",
       " ((9, 38), 24),\n",
       " ((9, 39), 15),\n",
       " ((9, 40), 12),\n",
       " ((9, 41), 15),\n",
       " ((9, 42), 12),\n",
       " ((9, 43), 14),\n",
       " ((9, 44), 9),\n",
       " ((9, 45), 6),\n",
       " ((9, 46), 12),\n",
       " ((9, 47), 14),\n",
       " ((9, 48), 4),\n",
       " ((9, 49), 12),\n",
       " ((9, 50), 10),\n",
       " ((9, 51), 9),\n",
       " ((9, 52), 3),\n",
       " ((9, 53), 6),\n",
       " ((9, 54), 7),\n",
       " ((9, 55), 1),\n",
       " ((9, 56), 3),\n",
       " ((9, 57), 3),\n",
       " ((9, 58), 3),\n",
       " ((9, 59), 2),\n",
       " ((9, 60), 2),\n",
       " ((9, 61), 5),\n",
       " ((9, 62), 5),\n",
       " ((9, 63), 6),\n",
       " ((9, 64), 5),\n",
       " ((9, 65), 2),\n",
       " ((9, 66), 3),\n",
       " ((9, 67), 1),\n",
       " ((9, 68), 4),\n",
       " ((9, 70), 1),\n",
       " ((9, 71), 2),\n",
       " ((9, 73), 1),\n",
       " ((9, 76), 2),\n",
       " ((9, 77), 1),\n",
       " ((9, 78), 1),\n",
       " ((9, 79), 5),\n",
       " ((9, 80), 1),\n",
       " ((9, 81), 2),\n",
       " ((9, 83), 3),\n",
       " ((9, 85), 1),\n",
       " ((9, 88), 2),\n",
       " ((9, 90), 1),\n",
       " ((9, 93), 1),\n",
       " ((9, 103), 1),\n",
       " ((9, 104), 1),\n",
       " ((9, 106), 2),\n",
       " ((9, 112), 2),\n",
       " ((9, 114), 1),\n",
       " ((9, 115), 1),\n",
       " ((9, 116), 1),\n",
       " ((9, 123), 1),\n",
       " ((9, 143), 1),\n",
       " ((9, 169), 1),\n",
       " ((10, 1), 3),\n",
       " ((10, 2), 1),\n",
       " ((10, 3), 3),\n",
       " ((10, 4), 6),\n",
       " ((10, 5), 10),\n",
       " ((10, 6), 10),\n",
       " ((10, 7), 15),\n",
       " ((10, 8), 23),\n",
       " ((10, 9), 24),\n",
       " ((10, 10), 27),\n",
       " ((10, 11), 19),\n",
       " ((10, 12), 32),\n",
       " ((10, 13), 35),\n",
       " ((10, 14), 26),\n",
       " ((10, 15), 32),\n",
       " ((10, 16), 29),\n",
       " ((10, 17), 33),\n",
       " ((10, 18), 31),\n",
       " ((10, 19), 23),\n",
       " ((10, 20), 17),\n",
       " ((10, 21), 37),\n",
       " ((10, 22), 26),\n",
       " ((10, 23), 20),\n",
       " ((10, 24), 19),\n",
       " ((10, 25), 25),\n",
       " ((10, 26), 37),\n",
       " ((10, 27), 26),\n",
       " ((10, 28), 20),\n",
       " ((10, 29), 27),\n",
       " ((10, 30), 23),\n",
       " ((10, 31), 19),\n",
       " ((10, 32), 19),\n",
       " ((10, 33), 21),\n",
       " ((10, 34), 21),\n",
       " ((10, 35), 20),\n",
       " ((10, 36), 18),\n",
       " ((10, 37), 31),\n",
       " ((10, 38), 11),\n",
       " ((10, 39), 8),\n",
       " ((10, 40), 10),\n",
       " ((10, 41), 10),\n",
       " ((10, 42), 7),\n",
       " ((10, 43), 8),\n",
       " ((10, 44), 10),\n",
       " ((10, 45), 6),\n",
       " ((10, 46), 8),\n",
       " ((10, 47), 9),\n",
       " ((10, 48), 9),\n",
       " ((10, 49), 9),\n",
       " ((10, 50), 10),\n",
       " ((10, 51), 2),\n",
       " ((10, 52), 6),\n",
       " ((10, 53), 7),\n",
       " ((10, 54), 3),\n",
       " ((10, 55), 8),\n",
       " ((10, 56), 4),\n",
       " ((10, 57), 3),\n",
       " ((10, 58), 5),\n",
       " ((10, 59), 7),\n",
       " ((10, 60), 2),\n",
       " ((10, 61), 2),\n",
       " ((10, 62), 1),\n",
       " ((10, 63), 4),\n",
       " ((10, 64), 2),\n",
       " ((10, 65), 4),\n",
       " ((10, 66), 6),\n",
       " ((10, 67), 5),\n",
       " ((10, 68), 4),\n",
       " ((10, 69), 1),\n",
       " ((10, 70), 5),\n",
       " ((10, 71), 1),\n",
       " ((10, 72), 6),\n",
       " ((10, 73), 1),\n",
       " ((10, 76), 2),\n",
       " ((10, 77), 5),\n",
       " ((10, 78), 1),\n",
       " ((10, 81), 1),\n",
       " ((10, 82), 1),\n",
       " ((10, 84), 1),\n",
       " ((10, 86), 1),\n",
       " ((10, 88), 3),\n",
       " ((10, 89), 1),\n",
       " ((10, 92), 1),\n",
       " ((10, 94), 2),\n",
       " ((10, 101), 1),\n",
       " ((10, 106), 1),\n",
       " ((10, 121), 1),\n",
       " ((11, 1), 4),\n",
       " ((11, 3), 5),\n",
       " ((11, 4), 4),\n",
       " ((11, 5), 13),\n",
       " ((11, 6), 16),\n",
       " ((11, 7), 20),\n",
       " ((11, 8), 16),\n",
       " ((11, 9), 23),\n",
       " ((11, 10), 20),\n",
       " ((11, 11), 23),\n",
       " ((11, 12), 38),\n",
       " ((11, 13), 34),\n",
       " ((11, 14), 37),\n",
       " ((11, 15), 34),\n",
       " ((11, 16), 25),\n",
       " ((11, 17), 25),\n",
       " ((11, 18), 29),\n",
       " ((11, 19), 29),\n",
       " ((11, 20), 34),\n",
       " ((11, 21), 32),\n",
       " ((11, 22), 34),\n",
       " ((11, 23), 33),\n",
       " ((11, 24), 34),\n",
       " ((11, 25), 41),\n",
       " ((11, 26), 31),\n",
       " ((11, 27), 21),\n",
       " ((11, 28), 22),\n",
       " ((11, 29), 21),\n",
       " ((11, 30), 27),\n",
       " ((11, 31), 19),\n",
       " ((11, 32), 17),\n",
       " ((11, 33), 20),\n",
       " ((11, 34), 23),\n",
       " ((11, 35), 22),\n",
       " ((11, 36), 19),\n",
       " ((11, 37), 18),\n",
       " ((11, 38), 24),\n",
       " ((11, 39), 17),\n",
       " ((11, 40), 26),\n",
       " ((11, 41), 11),\n",
       " ((11, 42), 26),\n",
       " ((11, 43), 13),\n",
       " ((11, 44), 11),\n",
       " ((11, 45), 12),\n",
       " ((11, 46), 15),\n",
       " ((11, 47), 11),\n",
       " ((11, 48), 9),\n",
       " ((11, 49), 8),\n",
       " ((11, 50), 9),\n",
       " ((11, 51), 8),\n",
       " ((11, 52), 5),\n",
       " ((11, 53), 11),\n",
       " ((11, 54), 7),\n",
       " ((11, 55), 5),\n",
       " ((11, 56), 5),\n",
       " ((11, 57), 5),\n",
       " ((11, 58), 5),\n",
       " ((11, 59), 4),\n",
       " ((11, 60), 4),\n",
       " ((11, 61), 2),\n",
       " ((11, 62), 2),\n",
       " ((11, 63), 3),\n",
       " ((11, 64), 6),\n",
       " ((11, 65), 2),\n",
       " ((11, 66), 1),\n",
       " ((11, 67), 3),\n",
       " ((11, 68), 2),\n",
       " ((11, 69), 4),\n",
       " ((11, 70), 2),\n",
       " ((11, 71), 3),\n",
       " ((11, 72), 3),\n",
       " ((11, 73), 2),\n",
       " ((11, 74), 2),\n",
       " ((11, 75), 1),\n",
       " ((11, 76), 5),\n",
       " ((11, 77), 1),\n",
       " ((11, 78), 2),\n",
       " ((11, 80), 1),\n",
       " ((11, 81), 2),\n",
       " ((11, 82), 1),\n",
       " ((11, 83), 1),\n",
       " ((11, 84), 4),\n",
       " ((11, 87), 1),\n",
       " ((11, 89), 3),\n",
       " ((11, 91), 1),\n",
       " ((11, 93), 1),\n",
       " ((11, 101), 1),\n",
       " ((11, 110), 1),\n",
       " ((11, 141), 1),\n",
       " ((12, 1), 5),\n",
       " ((12, 3), 5),\n",
       " ((12, 4), 7),\n",
       " ((12, 5), 15),\n",
       " ((12, 6), 20),\n",
       " ((12, 7), 22),\n",
       " ((12, 8), 25),\n",
       " ((12, 9), 32),\n",
       " ((12, 10), 29),\n",
       " ((12, 11), 34),\n",
       " ((12, 12), 29),\n",
       " ((12, 13), 38),\n",
       " ((12, 14), 36),\n",
       " ((12, 15), 52),\n",
       " ((12, 16), 28),\n",
       " ((12, 17), 38),\n",
       " ((12, 18), 32),\n",
       " ((12, 19), 43),\n",
       " ((12, 20), 39),\n",
       " ((12, 21), 38),\n",
       " ((12, 22), 33),\n",
       " ((12, 23), 38),\n",
       " ((12, 24), 42),\n",
       " ((12, 25), 33),\n",
       " ((12, 26), 30),\n",
       " ((12, 27), 37),\n",
       " ((12, 28), 28),\n",
       " ((12, 29), 35),\n",
       " ((12, 30), 21),\n",
       " ((12, 31), 20),\n",
       " ((12, 32), 27),\n",
       " ((12, 33), 30),\n",
       " ((12, 34), 23),\n",
       " ((12, 35), 25),\n",
       " ((12, 36), 19),\n",
       " ((12, 37), 17),\n",
       " ((12, 38), 12),\n",
       " ((12, 39), 14),\n",
       " ((12, 40), 23),\n",
       " ((12, 41), 13),\n",
       " ((12, 42), 18),\n",
       " ((12, 43), 14),\n",
       " ((12, 44), 9),\n",
       " ((12, 45), 12),\n",
       " ((12, 46), 14),\n",
       " ((12, 47), 14),\n",
       " ((12, 48), 9),\n",
       " ((12, 49), 9),\n",
       " ((12, 50), 11),\n",
       " ((12, 51), 11),\n",
       " ((12, 52), 6),\n",
       " ((12, 53), 4),\n",
       " ((12, 54), 5),\n",
       " ((12, 55), 9),\n",
       " ((12, 56), 9),\n",
       " ((12, 57), 6),\n",
       " ((12, 58), 3),\n",
       " ((12, 59), 1),\n",
       " ((12, 60), 5),\n",
       " ((12, 61), 3),\n",
       " ((12, 62), 6),\n",
       " ((12, 63), 4),\n",
       " ((12, 64), 1),\n",
       " ((12, 65), 4),\n",
       " ((12, 66), 5),\n",
       " ((12, 67), 4),\n",
       " ((12, 68), 4),\n",
       " ((12, 69), 4),\n",
       " ((12, 70), 7),\n",
       " ((12, 71), 1),\n",
       " ((12, 72), 5),\n",
       " ((12, 73), 2),\n",
       " ((12, 74), 1),\n",
       " ((12, 75), 3),\n",
       " ((12, 76), 1),\n",
       " ((12, 77), 1),\n",
       " ((12, 79), 3),\n",
       " ((12, 80), 1),\n",
       " ((12, 81), 1),\n",
       " ((12, 82), 1),\n",
       " ((12, 83), 1),\n",
       " ((12, 85), 1),\n",
       " ((12, 86), 1),\n",
       " ((12, 87), 2),\n",
       " ((12, 88), 1),\n",
       " ((12, 89), 2),\n",
       " ((12, 93), 2),\n",
       " ((12, 94), 1),\n",
       " ((12, 95), 2),\n",
       " ((12, 97), 2),\n",
       " ((12, 101), 1),\n",
       " ((12, 103), 1),\n",
       " ((12, 109), 1),\n",
       " ((12, 112), 1),\n",
       " ((12, 158), 1),\n",
       " ((12, 164), 1),\n",
       " ((13, 1), 7),\n",
       " ((13, 2), 1),\n",
       " ((13, 3), 3),\n",
       " ((13, 4), 3),\n",
       " ((13, 5), 18),\n",
       " ((13, 6), 17),\n",
       " ((13, 7), 22),\n",
       " ((13, 8), 23),\n",
       " ((13, 9), 25),\n",
       " ((13, 10), 16),\n",
       " ((13, 11), 25),\n",
       " ((13, 12), 34),\n",
       " ((13, 13), 25),\n",
       " ((13, 14), 33),\n",
       " ((13, 15), 34),\n",
       " ((13, 16), 36),\n",
       " ((13, 17), 26),\n",
       " ((13, 18), 35),\n",
       " ((13, 19), 35),\n",
       " ((13, 20), 41),\n",
       " ((13, 21), 43),\n",
       " ((13, 22), 41),\n",
       " ((13, 23), 38),\n",
       " ((13, 24), 33),\n",
       " ((13, 25), 30),\n",
       " ((13, 26), 24),\n",
       " ((13, 27), 18),\n",
       " ((13, 28), 34),\n",
       " ((13, 29), 26),\n",
       " ((13, 30), 31),\n",
       " ((13, 31), 26),\n",
       " ((13, 32), 21),\n",
       " ((13, 33), 22),\n",
       " ((13, 34), 22),\n",
       " ((13, 35), 21),\n",
       " ((13, 36), 21),\n",
       " ((13, 37), 21),\n",
       " ((13, 38), 18),\n",
       " ((13, 39), 19),\n",
       " ((13, 40), 12),\n",
       " ((13, 41), 18),\n",
       " ((13, 42), 14),\n",
       " ((13, 43), 14),\n",
       " ((13, 44), 13),\n",
       " ((13, 45), 14),\n",
       " ((13, 46), 13),\n",
       " ((13, 47), 10),\n",
       " ((13, 48), 10),\n",
       " ((13, 49), 14),\n",
       " ((13, 50), 9),\n",
       " ((13, 51), 12),\n",
       " ((13, 52), 8),\n",
       " ((13, 53), 5),\n",
       " ((13, 54), 7),\n",
       " ((13, 55), 3),\n",
       " ((13, 56), 5),\n",
       " ((13, 58), 3),\n",
       " ((13, 59), 5),\n",
       " ((13, 60), 5),\n",
       " ((13, 61), 2),\n",
       " ((13, 62), 3),\n",
       " ((13, 63), 3),\n",
       " ((13, 64), 5),\n",
       " ((13, 65), 1),\n",
       " ((13, 66), 2),\n",
       " ((13, 68), 1),\n",
       " ((13, 69), 2),\n",
       " ((13, 70), 3),\n",
       " ((13, 71), 4),\n",
       " ((13, 72), 3),\n",
       " ((13, 73), 2),\n",
       " ((13, 74), 3),\n",
       " ((13, 75), 3),\n",
       " ((13, 76), 6),\n",
       " ((13, 77), 1),\n",
       " ((13, 78), 3),\n",
       " ((13, 79), 2),\n",
       " ((13, 80), 1),\n",
       " ((13, 83), 1),\n",
       " ((13, 84), 1),\n",
       " ((13, 85), 1),\n",
       " ((13, 87), 1),\n",
       " ((13, 88), 2),\n",
       " ((13, 92), 1),\n",
       " ((13, 95), 1),\n",
       " ((13, 97), 1),\n",
       " ((13, 98), 1),\n",
       " ((13, 103), 1),\n",
       " ((13, 104), 1),\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of all buckets: 6491 (# sent: 49866)\n",
      "# of buckets with counts < 32 filtered out: 283 (num sent: 10654)\n",
      "percent of examples remaining after filtering: 21.37\n"
     ]
    }
   ],
   "source": [
    "num_sent = lambda sent: reduce(lambda a, b: a + b, map(lambda x: x[1], sent))\n",
    "num_all = num_sent(all_buckets)\n",
    "num_batched = num_sent(batched_buckets)\n",
    "print(\"# of all buckets: %d (# sent: %d)\" % (len(all_buckets), num_all))\n",
    "print(\"# of buckets with counts < %d filtered out: %d (num sent: %d)\" % (batch_size, len(batched_buckets), num_batched))\n",
    "print(\"percent of examples remaining after filtering: %.2f\" % (100.0*num_batched/num_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_sorted_buckets(buckets):\n",
    "    b = sorted(buckets, key=operator.itemgetter(0, 1))\n",
    "    for i in b:\n",
    "        print(i)\n",
    "\n",
    "print_sorted_buckets(batched_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TwoDBisect:\n",
    "    def __init__(self, buckets):\n",
    "        self.buckets = sorted(buckets, key=operator.itemgetter(0, 1))\n",
    "        self.x, self.y = zip(*buckets)\n",
    "        self.x, self.y = np.array(list(self.x)), np.array(list(self.y))\n",
    "        \n",
    "    def twod_bisect(self, source, target):    \n",
    "        offset1 = np.searchsorted(self.x, len(source), side='left')\n",
    "        offset2 = np.where(self.y[offset1:] >= len(target))[0]        \n",
    "        return self.buckets[offset2[0]]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sent_len = lambda x: map(lambda y: len(y), x)\n",
    "max_len = lambda x: max(sent_len(x))\n",
    "min_len = lambda x: min(sent_len(x))\n",
    "\n",
    "min_len = min(min(sent_len(src_sent)), min(sent_len(targ_sent)))\n",
    "max_len = max(max(sent_len(src_sent)), max(sent_len(targ_sent)))\n",
    "\n",
    "# min_len = min\n",
    "# max_len = 65\n",
    "increment = 5\n",
    "\n",
    "all_pairs = [(i, j) for i in range(\n",
    "        min_len,max_len+increment,increment\n",
    "    ) for j in range(\n",
    "        min_len,max_len+increment,increment\n",
    "    )]\n",
    "\n",
    "\n",
    "bisect = TwoDBisect(buckets=all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tuples = []\n",
    "\n",
    "for src, targ in zip(src_sent, targ_sent):\n",
    "    try:\n",
    "        len_tup = bisect.twod_bisect(src, targ)\n",
    "        tuples.append(len_tup)\n",
    "    except Exception as e:\n",
    "        print(\"src length: %d\" % len(src))\n",
    "        print(\"targ length: %d\" % len(targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "counts = list(Counter(tuples).items())\n",
    "batch_size = 32\n",
    "filter_smaller_counts_than = batch_size\n",
    "\n",
    "c_sorted = sorted(counts, key=operator.itemgetter(0, 1))\n",
    "buckets = [i for i in c_sorted if i[1] >= filter_smaller_counts_than]\n",
    "print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TwoDBisect:\n",
    "    def __init__(self, buckets):\n",
    "        self.buckets = sorted(buckets, key=operator.itemgetter(0, 1))\n",
    "        self.x, self.y = zip(*buckets)\n",
    "        self.x, self.y = np.array(list(self.x)), np.array(list(self.y))\n",
    "        \n",
    "    def twod_bisect(self, source, target):    \n",
    "        offset1 = np.searchsorted(self.x, len(source), side='left')\n",
    "        offset2 = np.where(self.y[offset1:] >= len(target))[0]        \n",
    "        return self.buckets[offset2[0]]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class BucketSeq2SeqIter(DataIter):\n",
    "    \"\"\"Simple bucketing iterator for sequence-to-sequence models.\n",
    "    \n",
    "    @staticmethod\n",
    "    def \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source_seq : list of list of int\n",
    "    target_seq : list of list of int\n",
    "    batch_size : int\n",
    "        batch_size of data    \n",
    "    invalid_label : int, default -1\n",
    "        key for invalid label, e.g. <end-of-sentence>\n",
    "    dtype : str, default 'float32'\n",
    "        data type\n",
    "    buckets : list of pairs of int (source seq length, target seq length)\n",
    "        size of data buckets. Automatically generated if None.\n",
    "    data_name : str, default 'data'\n",
    "        name of data    print(buckets)\n",
    "    label_name : str, default 'softmax_label'\n",
    "        name of label\n",
    "    layout : str\n",
    "        format of data and label. 'NT' means (batch_size, length)\n",
    "        and 'TN' means (length, batch_size).\n",
    "    \"\"\"\n",
    "    def __init__(self, source, target, batch_size, buckets=None, invalid_label=-1,\n",
    "                 data_name='data', label_name='softmax_label', dtype='float32',\n",
    "                 layout='NTC', min_sent_len = 1, max_sent_len = 60):\n",
    "        super(BucketSeq2SeqIter, self).__init__()\n",
    "        \n",
    "        # insert call to gen_buckets here if buckets are not provided\n",
    "        if not buckets:\n",
    "            all_pairs = [(i, j) for i in range(\n",
    "                min_len,max_len+increment,increment\n",
    "            ) for j in range(\n",
    "                min_len,max_len+increment,increment\n",
    "            )]\n",
    "            self.bisect = TwoDBisect(buckets = all_pairs)\n",
    "            buckets = \n",
    "            \n",
    "#             [i for i, j in enumerate(np.bincount([len(s) for s in sentences]))\n",
    "#                        if j >= batch_size]\n",
    "            \n",
    "        # Sorting is kinda pointless because it's first by the first element of the tuple,\n",
    "        # then the next. So, it could be [(1, 2), (1, 20), (2, 5), (2, 71)]\n",
    "#         buckets.sort()\n",
    "\n",
    "        ndiscard = 0\n",
    "        self.data = [[] for _ in buckets]\n",
    "        for i, sent in enumerate(sentences):\n",
    "            \n",
    "            # this bisect also won't work because it's now based on a tuple of lengths\n",
    "            buck = bisect.bisect_left(buckets, len(sent))\n",
    "            # this test is not appropriate because of the tuple of lengths\n",
    "            if buck == len(buckets):\n",
    "                ndiscard += 1\n",
    "                continue\n",
    "            buff = np.full((buckets[buck],), invalid_label, dtype=dtype)\n",
    "            buff[:len(sent)] = sent\n",
    "            self.data[buck].append(buff)\n",
    "\n",
    "        self.data = [np.asarray(i, dtype=dtype) for i in self.data]\n",
    "\n",
    "        print(\"WARNING: discarded %d sentences longer than the largest bucket.\"%ndiscard)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.buckets = buckets\n",
    "        self.data_name = data_name\n",
    "        self.label_name = label_name\n",
    "        self.dtype = dtype\n",
    "        self.invalid_label = invalid_label\n",
    "        self.nddata = []\n",
    "        self.ndlabel = []\n",
    "        self.major_axis = layout.find('N')\n",
    "        self.default_bucket_key = max(buckets)\n",
    "\n",
    "        if self.major_axis == 0:\n",
    "            self.provide_data = [(data_name, (batch_size, self.default_bucket_key))]\n",
    "            self.provide_label = [(label_name, (batch_size, self.default_bucket_key))]\n",
    "        elif self.major_axis == 1:\n",
    "            self.provide_data = [(data_name, (self.default_bucket_key, batch_size))]\n",
    "            self.provide_label = [(label_name, (self.default_bucket_key, batch_size))]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid layout %s: Must by NT (batch major) or TN (time major)\")\n",
    "\n",
    "        self.idx = []\n",
    "        for i, buck in enumerate(self.data):\n",
    "            self.idx.extend([(i, j) for j in range(0, len(buck) - batch_size + 1, batch_size)])\n",
    "        self.curr_idx = 0\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.curr_idx = 0\n",
    "        random.shuffle(self.idx)\n",
    "        for buck in self.data:\n",
    "            np.random.shuffle(buck)\n",
    "\n",
    "        self.nddata = []\n",
    "        self.ndlabel = []\n",
    "        for buck in self.data:\n",
    "            label = np.empty_like(buck)\n",
    "            label[:, :-1] = buck[:, 1:]\n",
    "            label[:, -1] = self.invalid_label\n",
    "            self.nddata.append(ndarray.array(buck, dtype=self.dtype))\n",
    "            self.ndlabel.append(ndarray.array(label, dtype=self.dtype))\n",
    "\n",
    "    def next(self):\n",
    "        if self.curr_idx == len(self.idx):\n",
    "            raise StopIteration\n",
    "        i, j = self.idx[self.curr_idx]\n",
    "        self.curr_idx += 1\n",
    "\n",
    "        if self.major_axis == 1:\n",
    "            data = self.nddata[i][j:j+self.batch_size].T\n",
    "            label = self.ndlabel[i][j:j+self.batch_size].T\n",
    "        else:\n",
    "            data = self.nddata[i][j:j+self.batch_size]\n",
    "            label = self.ndlabel[i][j:j+self.batch_size]\n",
    "\n",
    "        return DataBatch([data], [label],\n",
    "                         bucket_key=self.buckets[i],\n",
    "                         provide_data=[(self.data_name, data.shape)],\n",
    "                         provide_label=[(self.label_name, label.shape)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(batched_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "buckets = list(range(5, 60, 5))\n",
    "#[10, 20, 30, 40, 50, 60]\n",
    "\n",
    "                 data_name='data', label_name='softmax_label', dtype='float32',\n",
    "start_label = 1\n",
    "invalid_label = 0\n",
    "\n",
    "def tokenize_text(fname, vocab=None, invalid_label=-1, start_label=0):\n",
    "    lines = open(fname).readlines()\n",
    "    lines = [filter(None, i.split(' ')) for i in lines]\n",
    "    sentences, vocab = mx.rnn.encode_sentences(lines, vocab=vocab, invalid_label=invalid_label, start_label=start_label)\n",
    "    return sentences, vocab\n",
    "\n",
    "def get_data(layout):\n",
    "    train_sent, vocab = tokenize_text(\"./data/ptb.train.txt\", start_label=start_label,\n",
    "                                      invalid_label=invalid_label)\n",
    "    val_sent, _ = tokenize_text(\"./data/ptb.test.txt\", vocab=vocab, start_label=start_label,\n",
    "                                invalid_label=invalid_label)\n",
    "\n",
    "    data_train  = mx.rnn.BucketSentenceIter(train_sent, args.batch_size, buckets=buckets,\n",
    "                                            invalid_label=invalid_label, layout=layout)\n",
    "    data_val    = mx.rnn.BucketSentenceIter(val_sent, args.batch_size, buckets=buckets,\n",
    "                                            invalid_label=invalid_label, layout=layout)\n",
    "    \n",
    "    print(\"default: %s\" % data_train.default_bucket_key)\n",
    "    return data_train, data_val, vocab\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    data_train, data_val, vocab = get_data('TN')\n",
    "    if args.stack_rnn:\n",
    "        stack = mx.rnn.SequentialRNNCell()\n",
    "        for layer in range(args.num_layers):\n",
    "            dropout = 0.0\n",
    "            if layer < (args.num_layers - 1):\n",
    "                dropout = args.dropout\n",
    "            stack.add(mx.rnn.FusedRNNCell(args.num_hidden, num_layers=1,\n",
    "                    mode='lstm', prefix='lstm_%d'%layer, dropout=dropout,\n",
    "                    bidirectional=args.bidirectional))\n",
    "        cell = stack\n",
    "    else:\n",
    "        cell = mx.rnn.FusedRNNCell(args.num_hidden, num_layers=args.num_layers, dropout=args.dropout,\n",
    "                mode='lstm', bidirectional=args.bidirectional)\n",
    "\n",
    "    def sym_gen(seq_len):\n",
    "        data = mx.sym.Variable('data')\n",
    "        label = mx.sym.Variable('softmax_label')\n",
    "        embed = mx.sym.Embedding(data=data, input_dim=len(vocab), output_dim=args.num_embed,name='embed')\n",
    "\n",
    "        output, _ = cell.unroll(seq_len, inputs=embed, merge_outputs=True, layout='TNC')\n",
    "\n",
    "        pred = mx.sym.Reshape(output,\n",
    "                shape=(-1, args.num_hidden*(1+args.bidirectional)))\n",
    "        pred = mx.sym.FullyConnected(data=pred, num_hidden=len(vocab), name='pred')\n",
    "\n",
    "        label = mx.sym.Reshape(label, shape=(-1,))\n",
    "        pred = mx.sym.SoftmaxOutput(data=pred, label=label, name='softmax')\n",
    "\n",
    "        return pred, ('data',), ('softmax_label',)\n",
    "\n",
    "    if args.gpus:\n",
    "        contexts = [mx.gpu(int(i)) for i in args.gpus.split(',')]\n",
    "    else:\n",
    "        contexts = mx.cpu(0)\n",
    "\n",
    "    model = mx.mod.BucketingModule(\n",
    "        sym_gen             = sym_gen,\n",
    "        default_bucket_key  = data_train.default_bucket_key,\n",
    "        context             = contexts)\n",
    "\n",
    "    if args.load_epoch:\n",
    "        _, arg_params, aux_params = mx.rnn.load_rnn_checkpoint(\n",
    "            cell, args.model_prefix, args.load_epoch)\n",
    "    else:\n",
    "        arg_params = None\n",
    "        aux_params = None\n",
    "\n",
    "    opt_params = {\n",
    "      'learning_rate': args.lr,\n",
    "      'wd': args.wd\n",
    "    }\n",
    "\n",
    "    if args.optimizer not in ['adadelta', 'adagrad', 'adam', 'rmsprop']:\n",
    "        opt_params['momentum'] = args.mom\n",
    "\n",
    "    model.fit(\n",
    "        train_data          = data_train,\n",
    "        eval_data           = data_val,\n",
    "        eval_metric         = mx.metric.Perplexity(invalid_label),\n",
    "        kvstore             = args.kv_store,\n",
    "        optimizer           = args.optimizer,\n",
    "        optimizer_params    = opt_params, \n",
    "        initializer         = mx.init.Xavier(factor_type=\"in\", magnitude=2.34),\n",
    "        arg_params          = arg_params,\n",
    "        aux_params          = aux_params,\n",
    "        begin_epoch         = args.load_epoch,\n",
    "        num_epoch           = args.num_epochs,\n",
    "        batch_end_callback  = mx.callback.Speedometer(args.batch_size, args.disp_batches),\n",
    "        epoch_end_callback  = mx.rnn.do_rnn_checkpoint(cell, args.model_prefix, 1)\n",
    "                              if args.model_prefix else None)\n",
    "\n",
    "def test(args):\n",
    "    assert args.model_prefix, \"Must specifiy path to load from\"\n",
    "    _, data_val, vocab = get_data('NT')\n",
    "\n",
    "    if not args.stack_rnn:\n",
    "        stack = mx.rnn.FusedRNNCell(args.num_hidden, num_layers=args.num_layers,\n",
    "                mode='lstm', bidirectional=args.bidirectionclass BucketSentenceIter(DataIter):\n",
    "    \"\"\"Simple bucketing iterator for language model.\n",
    "    Label for each step is constructed from data of\n",
    "    next step.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences : list of list of int\n",
    "        encoded sentences\n",
    "    batch_size : int\n",
    "        batch_size of data\n",
    "    invalid_label : int, default -1\n",
    "        key for invalid label, e.g. <end-of-sentence>\n",
    "    dtype : str, default 'float32'\n",
    "        data type\n",
    "    buckets : list of int\n",
    "        size of data buckets. Automatically generated if None.\n",
    "    data_name : str, default 'data'\n",
    "        name of data\n",
    "    label_name : str, default 'softmax_label'\n",
    "        name of label\n",
    "    layout : str\n",
    "        format of data and label. 'NT' means (batch_size, length)\n",
    "        and 'TN' means (length, batch_size).\n",
    "    \"\"\"\n",
    "    def __init__(self, sentences, batch_size, buckets=None, invalid_label=-1,\n",
    "                 data_name='data', label_name='softmax_label', dtype='float32',\n",
    "                 layout='NTC'):\n",
    "        super(BucketSentenceIter, self).__init__()\n",
    "        if not buckets:\n",
    "            buckets = [i for i, j in enumerate(np.bincount([len(s) for s in sentences]))\n",
    "                       if j >= batch_size]\n",
    "        buckets.sort()\n",
    "\n",
    "        ndiscard = 0\n",
    "        self.data = [[] for _ in buckets]\n",
    "        for i, sent in enumerate(sentences):\n",
    "            buck = bisect.bisect_left(buckets, len(sent))\n",
    "            if buck == len(buckets):\n",
    "                ndiscard += 1\n",
    "                continue\n",
    "            buff = np.full((buckets[buck],), invalid_label, dtype=dtype)\n",
    "            buff[:len(sent)] = sent\n",
    "            self.data[buck].append(buff)\n",
    "\n",
    "        self.data = [np.asarray(i, dtype=dtype) for i in self.data]\n",
    "\n",
    "        print(\"WARNING: discarded %d sentences longer than the largest bucket.\"%ndiscard)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.buckets = buckets\n",
    "        self.data_name = data_name\n",
    "        self.label_name = label_name\n",
    "        self.dtype = dtype\n",
    "        self.invalid_label = invalid_label\n",
    "        self.nddata = []\n",
    "        self.ndlabel = []\n",
    "        self.major_axis = layout.find('N')\n",
    "        self.default_bucket_key = max(buckets)\n",
    "\n",
    "        if self.major_axis == 0:\n",
    "            self.provide_data = [(data_name, (batch_size, self.default_bucket_key))]\n",
    "            self.provide_label = [(label_name, (batch_size, self.default_bucket_key))]\n",
    "        elif self.major_axis == 1:\n",
    "            self.provide_data = [(data_name, (self.default_bucket_key, batch_size))]\n",
    "            self.provide_label = [(label_name, (self.default_bucket_key, batch_size))]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid layout %s: Must by NT (batch major) or TN (time major)\")\n",
    "\n",
    "        self.idx = []\n",
    "        for i, buck in enumerate(self.data):\n",
    "            self.idx.extend([(i, j) for j in range(0, len(buck) - batch_size + 1, batch_size)])\n",
    "        self.curr_idx = 0\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.curr_idx = 0\n",
    "        random.shuffle(self.idx)\n",
    "        for buck in self.data:\n",
    "            np.random.shuffle(buck)\n",
    "\n",
    "        self.nddata = []\n",
    "        self.ndlabel = []\n",
    "        for buck in self.data:\n",
    "            label = np.empty_like(buck)\n",
    "            label[:, :-1] = buck[:, 1:]\n",
    "            label[:, -1] = self.invalid_label\n",
    "            self.nddata.append(ndarray.array(buck, dtype=self.dtype))\n",
    "            self.ndlabel.append(ndarray.array(label, dtype=self.dtype))\n",
    "\n",
    "    def next(self):\n",
    "        if self.curr_idx == len(self.idx):\n",
    "            raise StopIteration\n",
    "        i, j = self.idx[self.curr_idx]\n",
    "        self.curr_idx += 1\n",
    "\n",
    "        if self.major_axis == 1:\n",
    "            data = self.nddata[i][j:j+self.batch_size].T\n",
    "            label = self.ndlabel[i][j:j+self.batch_size].T\n",
    "        else:\n",
    "            data = self.nddata[i][j:j+self.batch_size]\n",
    "            label = self.ndlabel[i][j:j+self.batch_size]\n",
    "\n",
    "        return DataBatch([data], [label],\n",
    "                         bucket_key=self.buckets[i],\n",
    "                         provide_data=[(self.data_name, data.shape)],\n",
    "                         provide_label=[(self.label_name, label.shape)])al).unfuse()\n",
    "    else:\n",
    "        stack = mx.rnn.SequentialRNNCell()\n",
    "        for i in range(args.num_layers):\n",
    "            cell = mx.rnn.LSTMCell(num_hidden=args.num_hidden, prefix='lstm_%dl0_'%i)\n",
    "            if args.bidirectional:\n",
    "                cell = mx.rnn.BidirectionalCell(\n",
    "                        cell,\n",
    "                        mx.rnn.LSTMCell(num_hidden=args.num_hidden, prefix='lstm_%dr0_'%i),\n",
    "                        output_prefix='bi_lstm_%d'%i)\n",
    "            stack.add(cell)\n",
    "\n",
    "    def sym_gen(seq_len):\n",
    "        data = mx.sym.Variable('data')\n",
    "        label = mx.sym.Variable('softmax_label')\n",
    "        embed = mx.sym.Embedding(data=data, input_dim=len(vocab),\n",
    "                                 output_dim=args.num_embed, name='embed')\n",
    "\n",
    "        stack.reset()\n",
    "        outputs, states = stack.unroll(seq_len, inputs=embed, merge_outputs=True)\n",
    "\n",
    "        pred = mx.sym.Reshape(outputs,\n",
    "                shape=(-1, args.num_hidden*(1+args.bidirectional)))\n",
    "        pred = mx.sym.FullyConnected(data=pred, num_hidden=len(vocab), name='pred')\n",
    "\n",
    "        label = mx.sym.Reshape(label, shape=(-1,))\n",
    "        pred = mx.sym.SoftmaxOutput(data=pred, label=label, name='softmax')\n",
    "\n",
    "        return pred, ('data',), ('softmax_label',)\n",
    "    \n",
    "class BucketSentenceIter(DataIter):\n",
    "    \"\"\"Simple bucketing iterator for language model.\n",
    "    Label for each step is constructed from data of\n",
    "    next step.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences : list of list of int\n",
    "        encoded sentences\n",
    "    batch_size : int\n",
    "        batch_size of data\n",
    "    invalid_label : int, default -1\n",
    "        key for invalid label, e.g. <end-of-sentence>\n",
    "    dtype : str, default 'float32'\n",
    "        data type\n",
    "    buckets : list of int\n",
    "        size of data buckets. Automatically generated if None.\n",
    "    data_name : str, default 'data'\n",
    "        name of data\n",
    "    label_name : str, default 'softmax_label'\n",
    "        name of label\n",
    "    layout : str\n",
    "        format of data and label. 'NT' means (batch_size, length)\n",
    "        and 'TN' means (length, batch_size).\n",
    "    \"\"\"\n",
    "    def __init__(self, sentences, batch_size, buckets=None, invalid_label=-1,\n",
    "                 data_name='data', label_name='softmax_label', dtype='float32',\n",
    "                 layout='NTC'):\n",
    "        super(BucketSentenceIter, self).__init__()\n",
    "        if not buckets:\n",
    "            buckets = [i for i, j in enumerate(np.bincount([len(s) for s in sentences]))\n",
    "                       if j >= batch_size]\n",
    "        buckets.sort()\n",
    "\n",
    "        ndiscard = 0\n",
    "        self.data = [[] for _ in buckets]\n",
    "        for i, sent in enumerate(sentences):\n",
    "            buck = bisect.bisect_left(buckets, len(sent))\n",
    "            if buck == len(buckets):\n",
    "                ndiscard += 1\n",
    "                continue\n",
    "            buff = np.full((buckets[buck],), invalid_label, dtype=dtype)\n",
    "            buff[:len(sent)] = sent\n",
    "            self.data[buck].append(buff)\n",
    "\n",
    "        self.data = [np.asarray(i, dtype=dtype) for i in self.data]\n",
    "\n",
    "        print(\"WARNING: discarded %d sentences longer than the largest bucket.\"%ndiscard)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.buckets = buckets\n",
    "        self.data_name = data_name\n",
    "        self.label_name = label_name\n",
    "        self.dtype = dtype\n",
    "        self.invalid_label = invalid_label\n",
    "        self.nddata = []\n",
    "        self.ndlabel = []\n",
    "        self.major_axis = layout.find('N')\n",
    "        self.default_bucket_key = max(buckets)\n",
    "\n",
    "        if self.major_axis == 0:\n",
    "            self.provide_data = [(data_name, (batch_size, self.default_bucket_key))]\n",
    "            self.provide_label = [(label_name, (batch_size, self.default_bucket_key))]\n",
    "        elif self.major_axis == 1:\n",
    "            self.provide_data = [(data_name, (self.default_bucket_key, batch_size))]\n",
    "            self.provide_label = [(label_name, (self.default_bucket_key, batch_size))]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid layout %s: Must by NT (batch major) or TN (time major)\")\n",
    "\n",
    "        self.idx = []\n",
    "        for i, buck in enumerate(self.data):\n",
    "            self.idx.extend([(i, j) for j in range(0, len(buck) - batch_size + 1, batch_size)])\n",
    "        self.curr_idx = 0\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.curr_idx = 0\n",
    "        random.shuffle(self.idx)\n",
    "        for buck in self.data:\n",
    "            np.random.shuffle(buck)\n",
    "\n",
    "        self.nddata = []\n",
    "        self.ndlabel = []\n",
    "        for buck in self.data:\n",
    "            label = np.empty_like(buck)\n",
    "            label[:, :-1] = buck[:, 1:]\n",
    "            label[:, -1] = self.invalid_label\n",
    "            self.nddata.append(ndarray.array(buck, dtype=self.dtype))\n",
    "            self.ndlabel.append(ndarray.array(label, dtype=self.dtype))\n",
    "\n",
    "    def next(self):\n",
    "        if self.curr_idx == len(self.idx):\n",
    "            raise StopIteration\n",
    "        i, j = self.idx[self.curr_idx]\n",
    "        self.curr_idx += 1\n",
    "\n",
    "        if self.major_axis == 1:\n",
    "            data = self.nddata[i][j:j+self.batch_size].T\n",
    "            label = self.ndlabel[i][j:j+self.batch_size].T\n",
    "        else:\n",
    "            data = self.nddata[i][j:j+self.batch_size]\n",
    "            label = self.ndlabel[i][j:j+self.batch_size]\n",
    "\n",
    "        return DataBatch([data], [label],\n",
    "                         bucket_key=self.buckets[i],\n",
    "                         provide_data=[(self.data_name, data.shape)],\n",
    "                         provide_label=[(self.label_name, label.shape)])\n",
    "\n",
    "    if args.gpus:\n",
    "        contexts = [mx.gpu(int(i)) for i in args.gpus.split(',')]\n",
    "    else:\n",
    "        contexts = mx.cpu(0)\n",
    "\n",
    "    model = mx.mod.BucketingModule(\n",
    "        sym_gen             = sym_gen,\n",
    "        default_bucket_key  = data_val.default_bucket_key,\n",
    "        context             = contexts)\n",
    "    model.bind(data_val.provide_data, data_val.provide_label, for_training=False)\n",
    "\n",
    "    # note here we load using SequentialRNNCell instead of FusedRNNCell.\n",
    "    _, arg_params, aux_params = mx.rnn.load_rnn_checkpoint(stack, args.model_prefix, args.load_epoch)\n",
    "    model.set_params(arg_params, aux_params)\n",
    "\n",
    "    model.score(data_val, mx.metric.Perplexity(invalid_label),\n",
    "                batch_end_callback=mx.callback.Speedometer(args.batch_size, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "if args.num_layers >= 4 and len(args.gpus.split(',')) >= 4 and not args.stack_rnn:\n",
    "    print('WARNING: stack-rnn is recommended to train complex model on multiple GPUs')\n",
    "\n",
    "if args.test:\n",
    "    # Demonstrates how to load a model trained with CuDNN RNN and predict\n",
    "    # with non-fused MXNet symbol\n",
    "    test(args)\n",
    "else:\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class BucketSeq2SeqIter(DataIter):\n",
    "    \"\"\"Simple bucketing iterator for sequence-to-sequence models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences : list of list of pairs of int\n",
    "        encoded sentences (source seq dict int, target seq dict int)\n",
    "    batch_size : int\n",
    "        batch_size of data    \n",
    "    invalid_label : int, default -1\n",
    "        key for invalid label, e.g. <end-of-sentence>\n",
    "    dtype : str, default 'float32'\n",
    "        data type\n",
    "    buckets : list of pairs of int (source seq length, target seq length)\n",
    "        size of data buckets. Automatically generated if None.\n",
    "    data_name : str, default 'data'\n",
    "        name of data    print(buckets)\n",
    "    label_name : str, default 'softmax_label'\n",
    "        name of label\n",
    "    layout : str\n",
    "        format of data and label. 'NT' means (batch_size, length)\n",
    "        and 'TN' means (length, batch_size).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_seq, output_seq, batch_size, buckets=None, invalid_label=-1,\n",
    "                 data_name='data', label_name='softmax_label', dtype='float32',\n",
    "                 layout='NTC'):\n",
    "        super(BucketSentenceIter, self).__init__()\n",
    "        if not buckets:\n",
    "            buckets = [i for i, j in enumerate(np.bincount([len(s) for s in sentences]))\n",
    "                       if j >= batch_size]\n",
    "        buckets.sort()\n",
    "\n",
    "        ndiscard = 0\n",
    "        self.data = [[] for _ in buckets]\n",
    "        for i, sent in enumerate(sentences):\n",
    "            buck = bisect.bisect_left(buckets, len(sent))\n",
    "            if buck == len(buckets):\n",
    "                ndiscard += 1\n",
    "                continue\n",
    "            buff = np.full((buckets[buck],), invalid_label, dtype=dtype)\n",
    "            buff[:len(sent)] = sent\n",
    "            self.data[buck].append(buff)\n",
    "\n",
    "        self.data = [np.asarray(i, dtype=dtype) for i in self.data]\n",
    "\n",
    "        print(\"WARNING: discarded %d sentences longer than the largest bucket.\"%ndiscard)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.buckets = buckets\n",
    "        self.data_name = data_name\n",
    "        self.label_name = label_name\n",
    "        self.dtype = dtype\n",
    "        self.invalid_label = invalid_label\n",
    "        self.nddata = []\n",
    "        self.ndlabel = []\n",
    "        self.major_axis = layout.find('N')\n",
    "        self.default_bucket_key = max(buckets)\n",
    "\n",
    "        if self.major_axis == 0:\n",
    "            self.provide_data = [(data_name, (batch_size, self.default_bucket_key))]\n",
    "            self.provide_label = [(label_name, (batch_size, self.default_bucket_key))]\n",
    "        elif self.major_axis == 1:\n",
    "            self.provide_data = [(data_name, (self.default_bucket_key, batch_size))]\n",
    "            self.provide_label = [(label_name, (self.default_bucket_key, batch_size))]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid layout %s: Must by NT (batch major) or TN (time major)\")\n",
    "\n",
    "        self.idx = []\n",
    "        for i, buck in enumerate(self.data):\n",
    "            self.idx.extend([(i, j) for j in range(0, len(buck) - batch_size + 1, batch_size)])\n",
    "        self.curr_idx = 0\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.curr_idx = 0\n",
    "        random.shuffle(self.idx)\n",
    "        for buck in self.data:\n",
    "            np.random.shuffle(buck)\n",
    "\n",
    "        self.nddata = []\n",
    "        self.ndlabel = []\n",
    "        for buck in self.data:\n",
    "            label = np.empty_like(buck)\n",
    "            label[:, :-1] = buck[:, 1:]\n",
    "            label[:, -1] = self.invalid_label\n",
    "            self.nddata.append(ndarray.array(buck, dtype=self.dtype))\n",
    "            self.ndlabel.append(ndarray.array(label, dtype=self.dtype))\n",
    "\n",
    "    def next(self):\n",
    "        if self.curr_idx == len(self.idx):\n",
    "            raise StopIteration\n",
    "        i, j = self.idx[self.curr_idx]\n",
    "        self.curr_idx += 1\n",
    "\n",
    "        if self.major_axis == 1:\n",
    "            data = self.nddata[i][j:j+self.batch_size].T\n",
    "            label = self.ndlabel[i][j:j+self.batch_size].T\n",
    "        else:\n",
    "            data = self.nddata[i][j:j+self.batch_size]\n",
    "            label = self.ndlabel[i][j:j+self.batch_size]\n",
    "\n",
    "        return DataBatch([data], [label],\n",
    "                         bucket_key=self.buckets[i],\n",
    "                         provide_data=[(self.data_name, data.shape)],\n",
    "                         provide_label=[(self.label_name, label.shape)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class AttentionEncoderCell(BaseRNNCell):\n",
    "   \"\"\"Place holder cell that prepare input for attention decoders\"\"\"\n",
    "   def __init__(self, prefix='encode_', params=None):\n",
    "       super(AttentionEncoderCell, self).__init__(prefix, params=params)\n",
    "\n",
    "   @property\n",
    "   def state_shape(self):\n",
    "       return []\n",
    "\n",
    "   def __call__(self, inputs, states):\n",
    "       return inputs, states + [symbol.expand_dims(inputs, axis=1)]\n",
    "\n",
    "   def unroll(self, length, inputs, begin_state=None, layout='NTC', merge_outputs=None):\n",
    "       outputs = _normalize_sequence(length, inputs, layout, merge_outputs)\n",
    "       if merge_outputs is True:\n",
    "           states = outputs\n",
    "       else:\n",
    "           states = inputs\n",
    "\n",
    "       # attention cell always use NTC layout for states\n",
    "       states, _ = _normalize_sequence(None, states, 'NTC', True, layout)\n",
    "       return outputs, [states]\n",
    "\n",
    "\n",
    "def _attention_pooling(source, scores):\n",
    "   # source: (batch_size, seq_len, encoder_num_hidden)\n",
    "   # scores: (batch_size, seq_len, 1)\n",
    "   probs = symbol.softmax(scores, axis=1)\n",
    "   output = symbol.batch_dot(source, probs, transpose_a=True)\n",
    "   return symbol.reshape(output, shape=(0, 0))\n",
    "\n",
    "\n",
    "class BaseAttentionCell(BaseRNNCell):\n",
    "   \"\"\"Base class for attention cells\"\"\"\n",
    "   def __init__(self, prefix='att_', params=None):\n",
    "       super(BaseAttentionCell, self).__init__(prefix, params=params)\n",
    "\n",
    "   @property\n",
    "   def state_shape(self):\n",
    "       return [(0, 0, 0)]\n",
    "\n",
    "   def __call__(self, inputs, states):\n",
    "       raise NotImplementedError\n",
    "\n",
    "\n",
    "class DotAttentionCell(BaseAttentionCell):\n",
    "   \"\"\"Dot attention\"\"\"\n",
    "   def __init__(self, prefix='dotatt_', params=None):\n",
    "       super(DotAttentionCell, self).__init__(prefix, params=params)\n",
    "\n",
    "   def __call__(self, inputs, states):\n",
    "       # inputs: (batch_size, decoder_num_hidden)\n",
    "       # for dot attention decoder_num_hidden must equal encoder_num_hidden\n",
    "       if len(states) > 1:\n",
    "           states = [symbol.concat(*states, dim=1)]\n",
    "\n",
    "       # source: (batch_size, seq_len, encoder_num_hidden)\n",
    "       source = states[0]\n",
    "       # (batch_size, decoder_num_hidden, 1)\n",
    "       inputs = symbol.expand_dims(inputs, axis=2)\n",
    "       # (batch_size, seq_len, 1)\n",
    "       scores = symbol.batch_dot(source, inputs)\n",
    "       # (batch_size, encoder_num_hidden)\n",
    "       return _attention_pooling(source, scores), states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class AttentionEncoderCell(BaseRNNCell):\n",
    "   \"\"\"Place holder cell that prepare input for attention decoders\"\"\"\n",
    "   def __init__(self, prefix='encode_', params=None):\n",
    "       super(AttentionEncoderCell, self).__init__(prefix, params=params)\n",
    "\n",
    "   @property\n",
    "   def state_shape(self):\n",
    "       return []\n",
    "\n",
    "   def __call__(self, inputs, states):\n",
    "       return inputs, states + [symbol.expand_dims(inputs, axis=1)]\n",
    "\n",
    "   def unroll(self, length, inputs, begin_state=None, layout='NTC', merge_outputs=None):\n",
    "       outputs = _normalize_sequence(length, inputs, layout, merge_outputs)\n",
    "       if merge_outputs is True:\n",
    "           states = outputs\n",
    "       else:\n",
    "           states = inputs\n",
    "\n",
    "       # attention cell always use NTC layout for states\n",
    "       states, _ = _normalize_sequence(None, states, 'NTC', True, layout)\n",
    "       return outputs, [states]\n",
    "\n",
    "\n",
    "def _attention_pooling(source, scores):\n",
    "   # source: (batch_size, seq_len, encoder_num_hidden)\n",
    "   # scores: (batch_size, seq_len, 1)\n",
    "   probs = symbol.softmax(scores, axis=1)\n",
    "   output = symbol.batch_dot(source, probs, transpose_a=True)\n",
    "   return symbol.reshape(output, shape=(0, 0))\n",
    "\n",
    "\n",
    "class BaseAttentionCell(BaseRNNCell):\n",
    "   \"\"\"Base class for attention cells\"\"\"\n",
    "   def __init__(self, prefix='att_', params=None):\n",
    "       super(BaseAttentionCell, self).__init__(prefix, params=params)\n",
    "\n",
    "   @property\n",
    "   def state_shape(self):\n",
    "       return [(0, 0, 0)]\n",
    "\n",
    "   def __call__(self, inputs, states):\n",
    "       raise NotImplementedError\n",
    "\n",
    "\n",
    "class DotAttentionCell(BaseAttentionCell):\n",
    "   \"\"\"Dot attention\"\"\"\n",
    "   def __init__(self, prefix='dotatt_', params=None):\n",
    "       super(DotAttentionCell, self).__init__(prefix, params=params)\n",
    "\n",
    "   def __call__(self, inputs, states):\n",
    "       # inputs: (batch_size, decoder_num_hidden)\n",
    "       # for dot attention decoder_num_hidden must equal encoder_num_hidden\n",
    "       if len(states) > 1:\n",
    "           states = [symbol.concat(*states, dim=1)]\n",
    "\n",
    "       # source: (batch_size, seq_len, encoder_num_hidden)\n",
    "       source = states[0]\n",
    "       # (batch_size, decoder_num_hidden, 1)\n",
    "       inputs = symbol.expand_dims(inputs, axis=2)\n",
    "       # (batch_size, seq_len, 1)\n",
    "       scores = symbol.batch_dot(source, inputs)\n",
    "       # (batch_size, encoder_num_hidden)\n",
    "       return _attention_pooling(source, scores), states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
