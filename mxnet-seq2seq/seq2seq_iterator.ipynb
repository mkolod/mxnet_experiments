{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-03-30 17:44:52.398851. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from collections import namedtuple, Counter\n",
    "from unidecode import unidecode\n",
    "from itertools import groupby\n",
    "from mxnet.io import DataIter\n",
    "from random import shuffle\n",
    "\n",
    "import deepdish as dd\n",
    "\n",
    "import operator\n",
    "import pickle\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get rid of annoying Python deprecation warnings from built-in JSON encoder\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Decode text as UTF-8\n",
    "# Remove diacritical signs and convert to Latin alphabet\n",
    "# Separate punctuation as separate \"words\"\n",
    "def tokenize_text(fname, vocab=None, invalid_label=0, start_label=1, sep_punctuation=True):\n",
    "    lines = unidecode(open(fname).read().decode('utf-8')).split('\\n')\n",
    "    lines = [x for x in lines if x]\n",
    "    lines = map(lambda x: re.findall(r\"\\w+|[^\\w\\s]\", x, re.UNICODE), lines)    \n",
    "    sentences, vocab = mx.rnn.encode_sentences(lines, vocab=vocab, invalid_label=invalid_label, start_label=start_label)\n",
    "    return sentences, vocab\n",
    "\n",
    "Dataset = namedtuple(\n",
    "    'Dataset', \n",
    "    ['src_sent', 'src_vocab', 'inv_src_vocab', 'targ_sent', 'targ_vocab', 'inv_targ_vocab'])\n",
    "\n",
    "def invert_dict(d):\n",
    "    return {v: k for k, v in d.iteritems()}\n",
    "\n",
    "\n",
    "def get_data(src_path, targ_path, start_label=1, invalid_label=0, pad_symbol='<PAD>'):\n",
    "    src_sent, src_vocab = tokenize_text(src_path, start_label=start_label,\n",
    "                                invalid_label=invalid_label)\n",
    "    \n",
    "    src_vocab[pad_symbol] = invalid_label\n",
    "    inv_src_vocab = invert_dict(src_vocab)\n",
    "\n",
    "    targ_sent, targ_vocab = tokenize_text(targ_path, start_label=start_label, #new_start+1,\n",
    "                                          invalid_label=invalid_label)\n",
    "    \n",
    "    targ_vocab[pad_symbol] = invalid_label\n",
    "    inv_targ_vocab = invert_dict(targ_vocab)\n",
    "    \n",
    "    return Dataset(\n",
    "        src_sent=src_sent, src_vocab=src_vocab, inv_src_vocab=inv_src_vocab,\n",
    "        targ_sent=targ_sent, targ_vocab=targ_vocab, inv_targ_vocab=inv_targ_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def persist_dataset(dataset, path):\n",
    "    with open(path, 'wb+') as fileobj:\n",
    "        pickle.dump(dataset, fileobj)\n",
    "        \n",
    "def load_dataset(path):\n",
    "    with open(path, 'rb') as fileobj:\n",
    "        return pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset = \\\n",
    "    get_data(\n",
    "        src_path='./data/europarl-v7.es-en.en_small',\n",
    "        targ_path='./data/europarl-v7.es-en.es_small',\n",
    "        start_label=1,\n",
    "        invalid_label=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TwoDBisect:\n",
    "    def __init__(self, buckets):\n",
    "        self.buckets = sorted(buckets, key=operator.itemgetter(0, 1))\n",
    "        self.x, self.y = zip(*buckets)\n",
    "        self.x, self.y = np.array(list(self.x)), np.array(list(self.y))\n",
    "\n",
    "    def twod_bisect(self, source, target):    \n",
    "        offset1 = np.searchsorted(self.x, len(source), side='left')\n",
    "        offset2 = np.where(self.y[offset1:] >= len(target))[0]        \n",
    "        return self.buckets[offset1 + offset2[0]] \n",
    "\n",
    "class Seq2SeqIterator:    \n",
    "    \n",
    "    def __init__(self, dataset, buckets=None, batch_size=32, max_sent_len=None):\n",
    "        self.src_sent = dataset.src_sent\n",
    "        self.targ_sent = dataset.targ_sent\n",
    "        if buckets:\n",
    "            z = zip(*buckets)\n",
    "            self.max_sent_len = max(max(z[0]), max(z[1]))\n",
    "        else:\n",
    "            self.max_sent_len = max_sent_len\n",
    "        if self.max_sent_len:\n",
    "            self.src_sent, self.targ_sent = self.filter_long_sent(\n",
    "                self.src_sent, self.targ_sent, self.max_sent_len) \n",
    "        self.src_vocab = dataset.src_vocab\n",
    "        self.targ_vocab = dataset.targ_vocab\n",
    "        self.inv_src_vocab = dataset.inv_src_vocab\n",
    "        self.inv_targ_vocab = dataset.inv_targ_vocab\n",
    "        # Can't filter smaller counts per bucket if those sentences still exist!\n",
    "        self.buckets = buckets if buckets else self.gen_buckets(\n",
    "            self.src_sent, self.targ_sent, filter_smaller_counts_than=1, max_sent_len=max_sent_len)\n",
    "        self.bisect = TwoDBisect(self.buckets)\n",
    "        self.max_sent_len = max_sent_len\n",
    "        self.pad_id = self.src_vocab['<PAD>']\n",
    "        # After bucketization, we should probably del self.src_sent and self.targ_sent\n",
    "        # to free up memory.\n",
    "        self.bucketed_data, self.bucket_idx_to_key = self.bucketize()\n",
    "        self.bucket_key_to_idx = invert_dict(dict(enumerate(self.bucket_idx_to_key)))\n",
    "        self.interbucket_idx = 0\n",
    "        self.intrabucket_idx = 0\n",
    "        self.bucket_iterator_indices = list(range(len(self.bucket_idx_to_key)))\n",
    "    \n",
    "    def bucketize(self):\n",
    "        tuples = []\n",
    "        ctr = 0\n",
    "        for src, targ in zip(self.src_sent, self.targ_sent):\n",
    "            len_tup = self.bisect.twod_bisect(src, targ)\n",
    "            rev_src = src[::-1] \n",
    "            tuples.append((src, targ, len_tup))\n",
    "            \n",
    "        sorted_tuples = sorted(tuples, key=operator.itemgetter(2))\n",
    "        grouped = groupby(sorted_tuples, lambda x: x[2])\n",
    "        bucketed_data = [] \n",
    "        bucket_idx_to_key = []\n",
    "        \n",
    "        for group in grouped:\n",
    "            \n",
    "            # get src and targ sentences, ignore the last elem of the tuple \n",
    "            # (the grouping key of (src_len, targ_len))\n",
    "            key, value = group[0], map(lambda x: x[:2], group[1])\n",
    "\n",
    "            # create padded representation\n",
    "            new_src = np.full((len(value), key[0]), self.pad_id, dtype=np.int32)\n",
    "            new_targ = np.full((len(value), key[1]), self.pad_id, dtype=np.int32)\n",
    "            \n",
    "            for idx, example in enumerate(value):\n",
    "                curr_src, curr_targ = example\n",
    "                rev_src = curr_src[::-1]\n",
    "                new_src[idx, :-(len(rev_src)+1):-1] = rev_src\n",
    "                new_targ[idx, :len(curr_targ)] = curr_targ\n",
    "                                \n",
    "            bucketed_data.append((new_src, new_targ))\n",
    "            bucket_idx_to_key.append(key)\n",
    "        return bucketed_data, bucket_idx_to_key\n",
    "    \n",
    "    def current_bucket_key(self):\n",
    "        return self.bucket_idx_to_key[self.interbucket_idx]\n",
    "    \n",
    "    def current_bucket_index(self):\n",
    "        return self.bucket_iterator_indices[self.interbucket_idx]\n",
    "\n",
    "    # shuffle the data within buckets, and reset iterator\n",
    "    def reset(self):\n",
    "        self.interbucket_idx = 0\n",
    "        self.intrabucket_idx = 0        \n",
    "        for idx in range(len(self.bucketed_data)):\n",
    "            current = self.bucketed_data[idx]\n",
    "            src, targ = current\n",
    "            indices = np.array(range(len(src)))\n",
    "            np.random.shuffle(indices)\n",
    "            src = src[indices]\n",
    "            targ = targ[indices]\n",
    "            self.bucketed_data[idx] = (src, targ)\n",
    "        shuffle(self.bucket_iterator_indices)\n",
    "    \n",
    "\n",
    "    # iterate over data\n",
    "    def next(self):\n",
    "        # raise StopIteration when done\n",
    "        pass        \n",
    "\n",
    "#     def next(self):\n",
    "#         if self.curr_idx == len(self.idx):\n",
    "#             raise StopIteration\n",
    "#         i, j = self.idx[self.curr_idx]\n",
    "#         self.curr_idx += 1\n",
    "\n",
    "#         if self.major_axis == 1:\n",
    "#             data = self.nddata[i][j:j+self.batch_size].T\n",
    "#             label = self.ndlabel[i][j:j+self.batch_size].T\n",
    "#         else:\n",
    "#             data = self.nddata[i][j:j+self.batch_size]\n",
    "#             label = self.ndlabel[i][j:j+self.batch_size]\n",
    "\n",
    "#         return DataBatch([data], [label], pad=0,\n",
    "#                          bucket_key=self.buckets[i],\n",
    "#                          provide_data=[(self.data_name, data.shape)],\n",
    "#                          provide_label=[(self.label_name, label.shape)])    \n",
    "    \n",
    "    @staticmethod \n",
    "    def filter_long_sent(src_sent, targ_sent, max_len):\n",
    "        result = filter(lambda x: len(x[0]) <= max_len and len(x[1]) <= max_len, zip(src_sent, targ_sent))\n",
    "        return zip(*result)\n",
    "\n",
    "    @staticmethod\n",
    "    def gen_buckets(src_sent, targ_sent, filter_smaller_counts_than=None, max_sent_len=60, min_sent_len=1):\n",
    "        length_pairs = map(lambda x: (len(x[0]), len(x[1])), zip(src_sent, targ_sent))\n",
    "        counts = list(Counter(length_pairs).items())\n",
    "        c_sorted = sorted(counts, key=operator.itemgetter(0, 1))\n",
    "        buckets = [i[0] for i in c_sorted if i[1] >= filter_smaller_counts_than and \n",
    "                   (max_sent_len is None or i[0][0] <= max_sent_len) and\n",
    "                   (max_sent_len is None or i[0][1] <= max_sent_len) and\n",
    "                   (min_sent_len is None or i[0][0] >= min_sent_len) and\n",
    "                   (min_sent_len is None or i[0][1] >= min_sent_len)]\n",
    "        return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "i1 = Seq2SeqIterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  561],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   70],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [  561],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [25151],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [ 4688],\n",
       "        [   36],\n",
       "        [ 4688],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [   36],\n",
       "        [  561],\n",
       "        [   36]], dtype=int32),\n",
       " array([[  811,  1281,    43,   689,   103,  1209,  8176,    66,    70,\n",
       "           498,    30],\n",
       "        [  822,    41,    42,   914,     4,   467,  4481,   650,    47,\n",
       "         13241,    30],\n",
       "        [  129,    31,   459,  2385,     8,  2204,  1098,   276,   546,\n",
       "           117,   129],\n",
       "        [  595,   214,  1315,    24,   332,   689,   103,  3542,     4,\n",
       "          5967,    30],\n",
       "        [ 1112,  1990,   513,  1901,    17,  1990,  3857,    19,    70,\n",
       "          3934,    30],\n",
       "        [ 4161,    43,   585,    24,   152, 12145,  1775,    59,  2503,\n",
       "          5641,    30],\n",
       "        [43466, 43467,   214,    59,   155, 11187,    11, 26931,    17,\n",
       "         84269,    30],\n",
       "        [  595,   230,  1496,    59,  2036,    11,   918,   337,    59,\n",
       "          2036,    30],\n",
       "        [  439,    78,   440,    11,    50,  3783,  2701,    17,   633,\n",
       "          1820,    30],\n",
       "        [  325,  1762,   337,  2214,   103,  3815,     4, 31779,   925,\n",
       "         24522,    30],\n",
       "        [ 1448,   134,    11,   317,   242,   103,   362,  1730,   120,\n",
       "           922,    30],\n",
       "        [12070,   242,    24,    41,   420,   481,    24,  2555,    66,\n",
       "          1380,    30],\n",
       "        [   98,  4979,   214,    59,    39,   933,    63,    70,   675,\n",
       "          2157,    30],\n",
       "        [  310,   971,  8646,   715,    70,  1119,   192,     4,    70,\n",
       "           632,    30],\n",
       "        [   98,  1318, 21781,     4,    86,  5346,  3232,   103,   319,\n",
       "          1100,    30],\n",
       "        [   98,  1221,   505,  8363,    66,    70,  3633,  1312,     4,\n",
       "         13493,    30],\n",
       "        [  963,    43,    52,  1315,   337,   922,     4,    70, 28781,\n",
       "         30718,    30],\n",
       "        [  528, 11677,  1285,   825,    70,  2305,     4,  2077,   204,\n",
       "           522,    30],\n",
       "        [  574,   363,    42, 42033,  1161,    30,   938,    78,  3537,\n",
       "           985,    30],\n",
       "        [  963,  1513,    11,   108,  1129,    11,    86, 10032,     4,\n",
       "          8743,    30],\n",
       "        [  540,  6120,     4,  3223,   303,  1783,  8649,    66,   501,\n",
       "          5977,    30],\n",
       "        [ 6215,   817, 10262,   915,  9012,  1628,   884,  5112,   165,\n",
       "         18348,    30],\n",
       "        [ 5874,   689,  1279,  4294,   108,   581,     2,  2009,     2,\n",
       "             9,    30],\n",
       "        [  938, 11531,   337,    19,    70,  5468,  8994,    19,    70,\n",
       "          1069,    30],\n",
       "        [ 1363,  1506,  1380, 13148,    66,  2467,     4,    32,    47,\n",
       "           381,    30],\n",
       "        [   45,  1099,   402,    11,   802,    24,    77, 20037,   103,\n",
       "          1730,    30],\n",
       "        [ 1192,   214,     8,  3180,   165,   564,    24,   125,     8,\n",
       "             9,    30],\n",
       "        [ 1448,  2140,    11,    66,  1355,     8, 81787,   214,   165,\n",
       "          1100,    30],\n",
       "        [  439,    78,   440,    11,    42, 55083,    66,    70,   395,\n",
       "           188,    30],\n",
       "        [   97,    98,   134,  6128,  1139,    70,   279,  1026,   237,\n",
       "          6129,   100],\n",
       "        [12555,     8,   648,     4,  7129,    70, 14681,    17,     8,\n",
       "         34234,    30],\n",
       "        [ 3989,    11,   230,  4694,    43, 16136,    66,   650,     2,\n",
       "         24287,    30],\n",
       "        [ 2644,    11,    86,  2017,  5533,   650,     8, 10700,  1783,\n",
       "          2273,    30],\n",
       "        [ 5407,   337,    24,  2098,   835,  1383,     2,  3019,  1796,\n",
       "         15754,    30],\n",
       "        [  963,    17,   230,   539,   214,    78,    24,   152,    66,\n",
       "          4467,    30],\n",
       "        [ 4696,   304, 15437,    70,   151,   472,    59, 13783,   165,\n",
       "          2968,    30],\n",
       "        [  574, 25249,     4, 40168,   200,  5699,   388,  9335,    17,\n",
       "         12031,    30],\n",
       "        [  310,   192,    11,  1436,  4577,    11,    41,   214,  1001,\n",
       "          1311,    30],\n",
       "        [ 2130,  2049,  5475,     2, 24529,   959,     4,    70,  2553,\n",
       "          3075,    30],\n",
       "        [   98,  2140,  3408,    43,  2519,     4,   884,    74,  8238,\n",
       "            51,    30],\n",
       "        [  574,   538,     2,  5175, 46487,  1984,  2310,   108,    70,\n",
       "          7657,    30],\n",
       "        [   45,   246,   402,    11,    42,  4547,   404,  3802,     8,\n",
       "           505,    30],\n",
       "        [ 3676, 88174,    19,  6821,    17,  4630, 36490,   282,    70,\n",
       "         49781,  3676]], dtype=int32))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1.reset()\n",
    "i1.bucketed_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "src_sent = dataset.src_sent\n",
    "targ_sent = dataset.targ_sent\n",
    "\n",
    "sent_len = lambda x: map(lambda y: len(y), x)\n",
    "max_len = lambda x: max(sent_len(x))\n",
    "min_len = lambda x: min(sent_len(x))\n",
    "\n",
    "min_len = min(min(sent_len(src_sent)), min(sent_len(targ_sent)))\n",
    "# max_len = max(max(sent_len(src_sent)), max(sent_len(targ_sent)))\n",
    "\n",
    "# min_len = min\n",
    "max_len = 65\n",
    "increment = 5\n",
    "\n",
    "all_pairs = [(i, j) for i in range(\n",
    "        min_len,max_len+increment,increment\n",
    "    ) for j in range(\n",
    "        min_len,max_len+increment,increment\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "i2 = Seq2SeqIterator(dataset, buckets=all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src, targ = i1.bucketed_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20,  2,  9, 42, 22,  4,  6, 21,  1, 29, 19, 35, 32, 10, 16,  8, 26,\n",
       "        7, 36, 28, 15, 38,  5, 31,  0, 41,  3, 25, 37, 30, 17, 23, 11, 18,\n",
       "       12, 34, 39, 33, 14, 27, 24, 13, 40])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.array(range(len(src)))\n",
    "np.random.shuffle(indices)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src, targ = i1.bucketed_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1448,   134,    11,   317,   242,   103,   362,  1730,   120,\n",
       "          922,    30],\n",
       "       [   97,    98,   134,  6128,  1139,    70,   279,  1026,   237,\n",
       "         6129,   100],\n",
       "       [   45,   246,   402,    11,    42,  4547,   404,  3802,     8,\n",
       "          505,    30],\n",
       "       [12555,     8,   648,     4,  7129,    70, 14681,    17,     8,\n",
       "        34234,    30],\n",
       "       [   98,  1318, 21781,     4,    86,  5346,  3232,   103,   319,\n",
       "         1100,    30],\n",
       "       [  574,   363,    42, 42033,  1161,    30,   938,    78,  3537,\n",
       "          985,    30],\n",
       "       [  963,    43,    52,  1315,   337,   922,     4,    70, 28781,\n",
       "        30718,    30],\n",
       "       [  938, 11531,   337,    19,    70,  5468,  8994,    19,    70,\n",
       "         1069,    30],\n",
       "       [  595,   214,  1315,    24,   332,   689,   103,  3542,     4,\n",
       "         5967,    30],\n",
       "       [  822,    41,    42,   914,     4,   467,  4481,   650,    47,\n",
       "        13241,    30],\n",
       "       [  963,  1513,    11,   108,  1129,    11,    86, 10032,     4,\n",
       "         8743,    30],\n",
       "       [  540,  6120,     4,  3223,   303,  1783,  8649,    66,   501,\n",
       "         5977,    30],\n",
       "       [ 4161,    43,   585,    24,   152, 12145,  1775,    59,  2503,\n",
       "         5641,    30],\n",
       "       [ 5874,   689,  1279,  4294,   108,   581,     2,  2009,     2,\n",
       "            9,    30],\n",
       "       [   98,  4979,   214,    59,    39,   933,    63,    70,   675,\n",
       "         2157,    30],\n",
       "       [  129,    31,   459,  2385,     8,  2204,  1098,   276,   546,\n",
       "          117,   129],\n",
       "       [ 4696,   304, 15437,    70,   151,   472,    59, 13783,   165,\n",
       "         2968,    30],\n",
       "       [  325,  1762,   337,  2214,   103,  3815,     4, 31779,   925,\n",
       "        24522,    30],\n",
       "       [ 6215,   817, 10262,   915,  9012,  1628,   884,  5112,   165,\n",
       "        18348,    30],\n",
       "       [ 1448,  2140,    11,    66,  1355,     8, 81787,   214,   165,\n",
       "         1100,    30],\n",
       "       [ 3989,    11,   230,  4694,    43, 16136,    66,   650,     2,\n",
       "        24287,    30],\n",
       "       [43466, 43467,   214,    59,   155, 11187,    11, 26931,    17,\n",
       "        84269,    30],\n",
       "       [   98,  1221,   505,  8363,    66,    70,  3633,  1312,     4,\n",
       "        13493,    30],\n",
       "       [  439,    78,   440,    11,    50,  3783,  2701,    17,   633,\n",
       "         1820,    30],\n",
       "       [12070,   242,    24,    41,   420,   481,    24,  2555,    66,\n",
       "         1380,    30],\n",
       "       [ 1363,  1506,  1380, 13148,    66,  2467,     4,    32,    47,\n",
       "          381,    30],\n",
       "       [ 2644,    11,    86,  2017,  5533,   650,     8, 10700,  1783,\n",
       "         2273,    30],\n",
       "       [  310,   971,  8646,   715,    70,  1119,   192,     4,    70,\n",
       "          632,    30],\n",
       "       [  963,    17,   230,   539,   214,    78,    24,   152,    66,\n",
       "         4467,    30],\n",
       "       [ 3676, 88174,    19,  6821,    17,  4630, 36490,   282,    70,\n",
       "        49781,  3676],\n",
       "       [  439,    78,   440,    11,    42, 55083,    66,    70,   395,\n",
       "          188,    30],\n",
       "       [ 1192,   214,     8,  3180,   165,   564,    24,   125,     8,\n",
       "            9,    30],\n",
       "       [  811,  1281,    43,   689,   103,  1209,  8176,    66,    70,\n",
       "          498,    30],\n",
       "       [  574,   538,     2,  5175, 46487,  1984,  2310,   108,    70,\n",
       "         7657,    30],\n",
       "       [  310,   192,    11,  1436,  4577,    11,    41,   214,  1001,\n",
       "         1311,    30],\n",
       "       [ 5407,   337,    24,  2098,   835,  1383,     2,  3019,  1796,\n",
       "        15754,    30],\n",
       "       [   98,  2140,  3408,    43,  2519,     4,   884,    74,  8238,\n",
       "           51,    30],\n",
       "       [ 1112,  1990,   513,  1901,    17,  1990,  3857,    19,    70,\n",
       "         3934,    30],\n",
       "       [  528, 11677,  1285,   825,    70,  2305,     4,  2077,   204,\n",
       "          522,    30],\n",
       "       [   45,  1099,   402,    11,   802,    24,    77, 20037,   103,\n",
       "         1730,    30],\n",
       "       [  574, 25249,     4, 40168,   200,  5699,   388,  9335,    17,\n",
       "        12031,    30],\n",
       "       [ 2130,  2049,  5475,     2, 24529,   959,     4,    70,  2553,\n",
       "         3075,    30],\n",
       "       [  595,   230,  1496,    59,  2036,    11,   918,   337,    59,\n",
       "         2036,    30]], dtype=int32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
