{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/json/encoder.py:207: DeprecationWarning: Interpreting naive datetime as local 2017-03-29 21:36:46.156794. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from collections import namedtuple, Counter\n",
    "from unidecode import unidecode\n",
    "from itertools import groupby\n",
    "from mxnet.io import DataIter\n",
    "from random import shuffle\n",
    "\n",
    "import deepdish as dd\n",
    "\n",
    "import operator\n",
    "import pickle\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of annoying Python deprecation warnings from built-in JSON encoder\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decode text as UTF-8\n",
    "# Remove diacritical signs and convert to Latin alphabet\n",
    "# Separate punctuation as separate \"words\"\n",
    "def tokenize_text(fname, vocab=None, invalid_label=0, start_label=1, sep_punctuation=True):\n",
    "    lines = unidecode(open(fname).read().decode('utf-8')).split('\\n')\n",
    "    lines = [x for x in lines if x]\n",
    "    lines = map(lambda x: re.findall(r\"\\w+|[^\\w\\s]\", x, re.UNICODE), lines)    \n",
    "    sentences, vocab = mx.rnn.encode_sentences(lines, vocab=vocab, invalid_label=invalid_label, start_label=start_label)\n",
    "    return sentences, vocab\n",
    "\n",
    "Dataset = namedtuple('Dataset', ['src_sent', 'src_vocab', 'targ_sent', 'targ_vocab'])\n",
    "\n",
    "def get_data(src_path, targ_path, start_label=1, invalid_label=0):\n",
    "    src_sent, src_vocab = tokenize_text(src_path, start_label=start_label,\n",
    "                                invalid_label=invalid_label)\n",
    "    \n",
    "    targ_sent, targ_vocab = tokenize_text(targ_path, start_label=start_label, #new_start+1,\n",
    "                                          invalid_label=invalid_label)\n",
    "\n",
    "    return Dataset(src_sent=src_sent, src_vocab=src_vocab, targ_sent=targ_sent, targ_vocab=targ_vocab)\n",
    "\n",
    "def persist_dataset(dataset, path):\n",
    "    with open(path, 'wb+') as fileobj:\n",
    "        pickle.dump(dataset, fileobj)\n",
    "        \n",
    "def load_dataset(path):\n",
    "    with open(path, 'rb') as fileobj:\n",
    "        return pickle.load(fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = \\\n",
    "    get_data(\n",
    "        src_path='./data/europarl-v7.es-en.en_small',\n",
    "        targ_path='./data/europarl-v7.es-en.es_small',\n",
    "        start_label=1,\n",
    "        invalid_label=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Seq2SeqIterator:    \n",
    "    \n",
    "    class TwoDBisect:\n",
    "        def __init__(self, buckets):\n",
    "            self.buckets = sorted(buckets, key=operator.itemgetter(0, 1))\n",
    "            self.x, self.y = zip(*buckets)\n",
    "            self.x, self.y = np.array(list(self.x)), np.array(list(self.y))\n",
    "\n",
    "        def twod_bisect(self, source, target):    \n",
    "            offset1 = np.searchsorted(self.x, len(source), side='left')\n",
    "            offset2 = np.where(self.y[offset1:] >= len(target))[0]        \n",
    "            return self.buckets[offset1 + offset2[0]] \n",
    "    \n",
    "    def __init__(self, dataset, buckets=None, batch_size=32):\n",
    "        self.buckets = buckets if buckets else self.gen_buckets(\n",
    "            dataset, filter_smaller_counts_than=batch_size)            \n",
    "    \n",
    "    @staticmethod\n",
    "    def gen_buckets(dataset, filter_smaller_counts_than=None, max_sent_len=60, min_sent_len=1):\n",
    "        src_sent = dataset.src_sent\n",
    "        targ_sent = dataset.targ_sent\n",
    "        length_pairs = map(lambda x: (len(x[0]), len(x[1])), zip(src_sent, targ_sent))\n",
    "        counts = list(Counter(length_pairs).items())\n",
    "        c_sorted = sorted(counts, key=operator.itemgetter(0, 1))\n",
    "        buckets = [i[0] for i in c_sorted if i[1] >= filter_smaller_counts_than and \n",
    "                   (max_sent_len is None or i[0][0] <= max_sent_len) and\n",
    "                   (max_sent_len is None or i[0][1] <= max_sent_len) and\n",
    "                   (min_sent_len is None or i[0][0] >= min_sent_len) and\n",
    "                   (min_sent_len is None or i[0][1] >= min_sent_len)]\n",
    "        return buckets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i1 = Seq2SeqIterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src_sent = dataset.src_sent\n",
    "targ_sent = dataset.targ_sent\n",
    "\n",
    "sent_len = lambda x: map(lambda y: len(y), x)\n",
    "max_len = lambda x: max(sent_len(x))\n",
    "min_len = lambda x: min(sent_len(x))\n",
    "\n",
    "min_len = min(min(sent_len(src_sent)), min(sent_len(targ_sent)))\n",
    "# max_len = max(max(sent_len(src_sent)), max(sent_len(targ_sent)))\n",
    "\n",
    "# min_len = min\n",
    "max_len = 65\n",
    "increment = 5\n",
    "\n",
    "all_pairs = [(i, j) for i in range(\n",
    "        min_len,max_len+increment,increment\n",
    "    ) for j in range(\n",
    "        min_len,max_len+increment,increment\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i2 = Seq2SeqIterator(dataset, all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (1, 6),\n",
       " (1, 11),\n",
       " (1, 16),\n",
       " (1, 21),\n",
       " (1, 26),\n",
       " (1, 31),\n",
       " (1, 36),\n",
       " (1, 41),\n",
       " (1, 46),\n",
       " (1, 51),\n",
       " (1, 56),\n",
       " (1, 61),\n",
       " (1, 66),\n",
       " (6, 1),\n",
       " (6, 6),\n",
       " (6, 11),\n",
       " (6, 16),\n",
       " (6, 21),\n",
       " (6, 26),\n",
       " (6, 31),\n",
       " (6, 36),\n",
       " (6, 41),\n",
       " (6, 46),\n",
       " (6, 51),\n",
       " (6, 56),\n",
       " (6, 61),\n",
       " (6, 66),\n",
       " (11, 1),\n",
       " (11, 6),\n",
       " (11, 11),\n",
       " (11, 16),\n",
       " (11, 21),\n",
       " (11, 26),\n",
       " (11, 31),\n",
       " (11, 36),\n",
       " (11, 41),\n",
       " (11, 46),\n",
       " (11, 51),\n",
       " (11, 56),\n",
       " (11, 61),\n",
       " (11, 66),\n",
       " (16, 1),\n",
       " (16, 6),\n",
       " (16, 11),\n",
       " (16, 16),\n",
       " (16, 21),\n",
       " (16, 26),\n",
       " (16, 31),\n",
       " (16, 36),\n",
       " (16, 41),\n",
       " (16, 46),\n",
       " (16, 51),\n",
       " (16, 56),\n",
       " (16, 61),\n",
       " (16, 66),\n",
       " (21, 1),\n",
       " (21, 6),\n",
       " (21, 11),\n",
       " (21, 16),\n",
       " (21, 21),\n",
       " (21, 26),\n",
       " (21, 31),\n",
       " (21, 36),\n",
       " (21, 41),\n",
       " (21, 46),\n",
       " (21, 51),\n",
       " (21, 56),\n",
       " (21, 61),\n",
       " (21, 66),\n",
       " (26, 1),\n",
       " (26, 6),\n",
       " (26, 11),\n",
       " (26, 16),\n",
       " (26, 21),\n",
       " (26, 26),\n",
       " (26, 31),\n",
       " (26, 36),\n",
       " (26, 41),\n",
       " (26, 46),\n",
       " (26, 51),\n",
       " (26, 56),\n",
       " (26, 61),\n",
       " (26, 66),\n",
       " (31, 1),\n",
       " (31, 6),\n",
       " (31, 11),\n",
       " (31, 16),\n",
       " (31, 21),\n",
       " (31, 26),\n",
       " (31, 31),\n",
       " (31, 36),\n",
       " (31, 41),\n",
       " (31, 46),\n",
       " (31, 51),\n",
       " (31, 56),\n",
       " (31, 61),\n",
       " (31, 66),\n",
       " (36, 1),\n",
       " (36, 6),\n",
       " (36, 11),\n",
       " (36, 16),\n",
       " (36, 21),\n",
       " (36, 26),\n",
       " (36, 31),\n",
       " (36, 36),\n",
       " (36, 41),\n",
       " (36, 46),\n",
       " (36, 51),\n",
       " (36, 56),\n",
       " (36, 61),\n",
       " (36, 66),\n",
       " (41, 1),\n",
       " (41, 6),\n",
       " (41, 11),\n",
       " (41, 16),\n",
       " (41, 21),\n",
       " (41, 26),\n",
       " (41, 31),\n",
       " (41, 36),\n",
       " (41, 41),\n",
       " (41, 46),\n",
       " (41, 51),\n",
       " (41, 56),\n",
       " (41, 61),\n",
       " (41, 66),\n",
       " (46, 1),\n",
       " (46, 6),\n",
       " (46, 11),\n",
       " (46, 16),\n",
       " (46, 21),\n",
       " (46, 26),\n",
       " (46, 31),\n",
       " (46, 36),\n",
       " (46, 41),\n",
       " (46, 46),\n",
       " (46, 51),\n",
       " (46, 56),\n",
       " (46, 61),\n",
       " (46, 66),\n",
       " (51, 1),\n",
       " (51, 6),\n",
       " (51, 11),\n",
       " (51, 16),\n",
       " (51, 21),\n",
       " (51, 26),\n",
       " (51, 31),\n",
       " (51, 36),\n",
       " (51, 41),\n",
       " (51, 46),\n",
       " (51, 51),\n",
       " (51, 56),\n",
       " (51, 61),\n",
       " (51, 66),\n",
       " (56, 1),\n",
       " (56, 6),\n",
       " (56, 11),\n",
       " (56, 16),\n",
       " (56, 21),\n",
       " (56, 26),\n",
       " (56, 31),\n",
       " (56, 36),\n",
       " (56, 41),\n",
       " (56, 46),\n",
       " (56, 51),\n",
       " (56, 56),\n",
       " (56, 61),\n",
       " (56, 66),\n",
       " (61, 1),\n",
       " (61, 6),\n",
       " (61, 11),\n",
       " (61, 16),\n",
       " (61, 21),\n",
       " (61, 26),\n",
       " (61, 31),\n",
       " (61, 36),\n",
       " (61, 41),\n",
       " (61, 46),\n",
       " (61, 51),\n",
       " (61, 56),\n",
       " (61, 61),\n",
       " (61, 66),\n",
       " (66, 1),\n",
       " (66, 6),\n",
       " (66, 11),\n",
       " (66, 16),\n",
       " (66, 21),\n",
       " (66, 26),\n",
       " (66, 31),\n",
       " (66, 36),\n",
       " (66, 41),\n",
       " (66, 46),\n",
       " (66, 51),\n",
       " (66, 56),\n",
       " (66, 61),\n",
       " (66, 66)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2.buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
